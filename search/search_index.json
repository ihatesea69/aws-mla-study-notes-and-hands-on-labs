{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AWS Certified Machine Learning Engineer Associate (MLA-C01)","text":"<p>Welcome to the study notes and hands-on labs for the AWS Certified Machine Learning Engineer Associate exam.</p>"},{"location":"#exam-overview","title":"Exam Overview","text":"Attribute Details Exam Code MLA-C01 Duration 170 minutes Questions 65 (50 scored + 15 unscored) Passing Score 720/1000 Question Types Multiple choice, Multiple response, Ordering, Matching Cost $150 USD"},{"location":"#content-domains","title":"Content Domains","text":"Domain Weight Description Domain 1 28% Data Preparation for Machine Learning Domain 2 26% ML Model Development Domain 3 22% Deployment and Orchestration of ML Workflows Domain 4 24% ML Solution Monitoring, Maintenance, and Security"},{"location":"#quick-navigation","title":"Quick Navigation","text":""},{"location":"#by-domain","title":"By Domain","text":"<ul> <li>Domain 1: Data Preparation - Ingest, transform, validate, and prepare data</li> <li>Domain 2: Model Development - Training, tuning, evaluation, versioning</li> <li>Domain 3: Deployment &amp; Orchestration - Endpoints, pipelines, CI/CD</li> <li>Domain 4: Monitoring &amp; Security - Monitoring, cost, security, compliance</li> </ul>"},{"location":"#resources","title":"Resources","text":"<ul> <li>AWS Services Reference</li> <li>Hands-On Labs</li> <li>Practice Exams</li> <li>Cheat Sheets</li> </ul>"},{"location":"#study-tips","title":"Study Tips","text":"<p>!!! tip \"Recommended Study Order\" 1. Review the exam domains and understand the weightings 2. Study each domain systematically 3. Complete hands-on labs to reinforce concepts 4. Take practice exams to identify weak areas 5. Review cheat sheets before the exam</p> <p>!!! warning \"Key Focus Areas\" - Amazon SageMaker is the core service - understand it deeply - Know when to use each SageMaker endpoint type - Understand MLOps concepts with SageMaker Pipelines - Security best practices (IAM, KMS, VPC)</p>"},{"location":"#official-resources","title":"Official Resources","text":"<ul> <li>AWS Exam Guide</li> <li>In-Scope AWS Services</li> <li>AWS Skill Builder</li> </ul>"},{"location":"API/","title":"API Documentation","text":""},{"location":"API/#authentication","title":"Authentication","text":"<p>All API requests require a Bearer token in the header:</p> <pre><code>Authorization: Bearer &lt;token&gt;\n</code></pre>"},{"location":"API/#endpoints","title":"Endpoints","text":""},{"location":"API/#users","title":"Users","text":""},{"location":"API/#get-users","title":"GET /users","text":"<p>Get a list of users.</p> <p>Response:</p> <pre><code>[\n  {\n    \"id\": 1,\n    \"name\": \"John Doe\",\n    \"email\": \"john@example.com\"\n  }\n]\n</code></pre>"},{"location":"API/#post-users","title":"POST /users","text":"<p>Create a new user.</p> <p>Request:</p> <pre><code>{\n  \"name\": \"Jane Doe\",\n  \"email\": \"jane@example.com\"\n}\n</code></pre>"},{"location":"API/#health-check","title":"Health Check","text":""},{"location":"API/#get-health","title":"GET /health","text":"<p>Check if the service is running.</p> <p>Response:</p> <pre><code>{\n  \"status\": \"ok\"\n}\n</code></pre>"},{"location":"ARCHITECTURE/","title":"Architecture","text":""},{"location":"ARCHITECTURE/#system-overview","title":"System Overview","text":"<p>Provide a high-level overview of the system architecture.</p>"},{"location":"ARCHITECTURE/#diagrams","title":"Diagrams","text":""},{"location":"ARCHITECTURE/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TD\n    User[User] --&gt;|HTTPS| Frontend[Frontend]\n    Frontend --&gt;|API| Backend[Backend API]\n    Backend --&gt;|Read/Write| DB[(Database)]\n    Backend --&gt;|Invoke| AI[AI Service]</code></pre>"},{"location":"ARCHITECTURE/#components","title":"Components","text":""},{"location":"ARCHITECTURE/#frontend","title":"Frontend","text":"<p>Description of the frontend architecture (e.g., React, Next.js).</p>"},{"location":"ARCHITECTURE/#backend","title":"Backend","text":"<p>Description of the backend architecture (e.g., FastAPI, Node.js).</p>"},{"location":"ARCHITECTURE/#database","title":"Database","text":"<p>Description of the data model and storage.</p>"},{"location":"ARCHITECTURE/#data-flow","title":"Data Flow","text":"<p>Describe how data flows through the system.</p>"},{"location":"DEPLOYMENT/","title":"Deployment Guide","text":""},{"location":"DEPLOYMENT/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Docker</li> <li>AWS CLI</li> <li>Terraform</li> </ul>"},{"location":"DEPLOYMENT/#local-deployment","title":"Local Deployment","text":"<ol> <li>Build the containers:</li> </ol> <pre><code>docker-compose build\n</code></pre> <ol> <li>Start the services:    <pre><code>docker-compose up\n</code></pre></li> </ol>"},{"location":"DEPLOYMENT/#production-deployment-aws","title":"Production Deployment (AWS)","text":"<ol> <li>Configure AWS credentials:</li> </ol> <pre><code>aws configure\n</code></pre> <ol> <li>Initialize Terraform:</li> </ol> <pre><code>cd infrastructure\nterraform init\n</code></pre> <ol> <li>Apply infrastructure changes:    <pre><code>terraform apply\n</code></pre></li> </ol>"},{"location":"DEPLOYMENT/#cicd-pipeline","title":"CI/CD Pipeline","text":"<p>Describe your CI/CD pipeline here (e.g., GitHub Actions, Jenkins).</p>"},{"location":"aws-services/","title":"AWS Services Reference","text":"<p>Quick reference for AWS services covered in the MLA-C01 exam.</p>"},{"location":"aws-services/#core-ml-services","title":"Core ML Services","text":"Service Description Key Use Cases SageMaker Full ML platform Training, deployment, MLOps Bedrock Foundation models GenAI, fine-tuning Glue ETL and data catalog Data preparation Comprehend/Rekognition AI services NLP, computer vision Other ML Services Specialized AI Lex, Polly, Personalize"},{"location":"aws-services/#service-categories","title":"Service Categories","text":""},{"location":"aws-services/#data-preparation","title":"Data Preparation","text":"<ul> <li>Amazon S3 - Object storage</li> <li>AWS Glue - ETL, data catalog</li> <li>Amazon Kinesis - Streaming data</li> <li>AWS Lake Formation - Data lake management</li> <li>Amazon Athena - Query service</li> </ul>"},{"location":"aws-services/#model-development","title":"Model Development","text":"<ul> <li>Amazon SageMaker - Training, tuning</li> <li>Amazon Bedrock - Foundation models</li> <li>SageMaker JumpStart - Pre-trained models</li> </ul>"},{"location":"aws-services/#deployment","title":"Deployment","text":"<ul> <li>SageMaker Endpoints - Inference</li> <li>Amazon ECR - Container registry</li> <li>AWS Lambda - Serverless compute</li> </ul>"},{"location":"aws-services/#orchestration","title":"Orchestration","text":"<ul> <li>SageMaker Pipelines - ML workflows</li> <li>AWS Step Functions - Orchestration</li> <li>Amazon MWAA - Apache Airflow</li> </ul>"},{"location":"aws-services/#monitoring","title":"Monitoring","text":"<ul> <li>Amazon CloudWatch - Metrics, logs</li> <li>AWS CloudTrail - Audit logging</li> <li>SageMaker Model Monitor - Drift detection</li> </ul>"},{"location":"aws-services/#security","title":"Security","text":"<ul> <li>AWS IAM - Access management</li> <li>AWS KMS - Encryption</li> <li>AWS Secrets Manager - Secrets</li> <li>Amazon Macie - Data protection</li> </ul>"},{"location":"aws-services/bedrock/","title":"Amazon Bedrock","text":""},{"location":"aws-services/bedrock/#overview","title":"Overview","text":"<p>Fully managed service for accessing foundation models via API.</p>"},{"location":"aws-services/bedrock/#available-foundation-models","title":"Available Foundation Models","text":"Provider Models Strengths Amazon Titan Text, Titan Embeddings Cost-effective, AWS-native Anthropic Claude 3 (Opus, Sonnet, Haiku) Complex reasoning, long context Meta Llama 3 Open weights, fine-tunable Mistral Mistral, Mixtral Efficient, multilingual Cohere Command, Embed RAG, enterprise Stability AI Stable Diffusion Image generation"},{"location":"aws-services/bedrock/#key-features","title":"Key Features","text":""},{"location":"aws-services/bedrock/#model-access","title":"Model Access","text":"<pre><code>import boto3\nimport json\n\nbedrock_runtime = boto3.client(\"bedrock-runtime\")\n\nresponse = bedrock_runtime.invoke_model(\n    modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n    body=json.dumps({\n        \"anthropic_version\": \"bedrock-2023-05-31\",\n        \"max_tokens\": 1000,\n        \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]\n    })\n)\n</code></pre>"},{"location":"aws-services/bedrock/#fine-tuning","title":"Fine-tuning","text":"<p>Customize models with your data.</p> Model Fine-tuning Support Titan Text Yes Llama 3 Yes Cohere Yes Claude No (as of 2024)"},{"location":"aws-services/bedrock/#guardrails","title":"Guardrails","text":"<p>Content moderation and safety.</p> <ul> <li>Topic blocking</li> <li>Content filters (hate, violence, etc.)</li> <li>PII detection and masking</li> <li>Word filters</li> </ul>"},{"location":"aws-services/bedrock/#knowledge-bases","title":"Knowledge Bases","text":"<p>RAG (Retrieval Augmented Generation).</p> <pre><code>graph LR\n    A[Documents] --&gt; B[Chunking]\n    B --&gt; C[Embeddings]\n    C --&gt; D[Vector Store]\n    E[Query] --&gt; F[Search]\n    D --&gt; F\n    F --&gt; G[Context + Query]\n    G --&gt; H[LLM]\n    H --&gt; I[Response]</code></pre>"},{"location":"aws-services/bedrock/#agents","title":"Agents","text":"<p>Autonomous task completion.</p> <ul> <li>Action groups (Lambda functions)</li> <li>Knowledge base integration</li> <li>Multi-step reasoning</li> </ul>"},{"location":"aws-services/bedrock/#pricing-model","title":"Pricing Model","text":"Pricing Type Description On-demand Pay per token Provisioned Reserved capacity Batch Async processing at discount"},{"location":"aws-services/bedrock/#use-cases","title":"Use Cases","text":"Use Case Recommended Approach Text generation Claude, Titan Text Embeddings Titan Embeddings, Cohere Embed RAG Knowledge Bases Automation Agents Image generation Stable Diffusion, Titan Image"},{"location":"aws-services/bedrock/#exam-focus-areas","title":"Exam Focus Areas","text":"<p>!!! warning \"Key Topics\" - When to use Bedrock vs SageMaker - Guardrails for content safety - Knowledge Bases for RAG patterns - Fine-tuning capabilities and limitations</p>"},{"location":"aws-services/comprehend-rekognition/","title":"Amazon Comprehend and Rekognition","text":""},{"location":"aws-services/comprehend-rekognition/#amazon-comprehend","title":"Amazon Comprehend","text":"<p>Natural Language Processing (NLP) service.</p>"},{"location":"aws-services/comprehend-rekognition/#key-features","title":"Key Features","text":"Feature Description Entity Recognition Identify people, places, organizations Sentiment Analysis Positive, negative, neutral, mixed Key Phrases Extract important phrases Language Detection Identify language PII Detection Find personal information Custom Classification Train custom models Custom Entities Train custom NER"},{"location":"aws-services/comprehend-rekognition/#example-usage","title":"Example Usage","text":"<pre><code>import boto3\n\ncomprehend = boto3.client(\"comprehend\")\n\n# Sentiment analysis\nresponse = comprehend.detect_sentiment(\n    Text=\"I love this product! It's amazing.\",\n    LanguageCode=\"en\"\n)\n# Returns: {\"Sentiment\": \"POSITIVE\", \"SentimentScore\": {...}}\n\n# Entity detection\nresponse = comprehend.detect_entities(\n    Text=\"Amazon was founded by Jeff Bezos in Seattle.\",\n    LanguageCode=\"en\"\n)\n# Returns entities: Amazon (ORGANIZATION), Jeff Bezos (PERSON), Seattle (LOCATION)\n\n# PII detection\nresponse = comprehend.detect_pii_entities(\n    Text=\"My email is john@example.com and phone is 555-1234.\",\n    LanguageCode=\"en\"\n)\n</code></pre>"},{"location":"aws-services/comprehend-rekognition/#comprehend-medical","title":"Comprehend Medical","text":"<p>Healthcare-specific NLP.</p> <ul> <li>Medical entity extraction</li> <li>RxNorm codes</li> <li>ICD-10 codes</li> <li>Protected health information (PHI)</li> </ul>"},{"location":"aws-services/comprehend-rekognition/#amazon-rekognition","title":"Amazon Rekognition","text":"<p>Computer vision service.</p>"},{"location":"aws-services/comprehend-rekognition/#key-features_1","title":"Key Features","text":"Feature Description Object Detection Identify objects in images Face Detection Detect and analyze faces Face Comparison Compare faces Celebrity Recognition Identify celebrities Text Detection Extract text from images Content Moderation Detect inappropriate content Custom Labels Train custom object detection"},{"location":"aws-services/comprehend-rekognition/#example-usage_1","title":"Example Usage","text":"<pre><code>import boto3\n\nrekognition = boto3.client(\"rekognition\")\n\n# Label detection\nresponse = rekognition.detect_labels(\n    Image={\"S3Object\": {\"Bucket\": \"bucket\", \"Name\": \"image.jpg\"}},\n    MaxLabels=10,\n    MinConfidence=80\n)\n\n# Face detection\nresponse = rekognition.detect_faces(\n    Image={\"S3Object\": {\"Bucket\": \"bucket\", \"Name\": \"photo.jpg\"}},\n    Attributes=[\"ALL\"]\n)\n\n# Content moderation\nresponse = rekognition.detect_moderation_labels(\n    Image={\"S3Object\": {\"Bucket\": \"bucket\", \"Name\": \"image.jpg\"}}\n)\n</code></pre>"},{"location":"aws-services/comprehend-rekognition/#video-analysis","title":"Video Analysis","text":"<pre><code># Start video analysis\nresponse = rekognition.start_label_detection(\n    Video={\"S3Object\": {\"Bucket\": \"bucket\", \"Name\": \"video.mp4\"}},\n    NotificationChannel={\n        \"SNSTopicArn\": sns_topic_arn,\n        \"RoleArn\": role_arn\n    }\n)\n\n# Get results\nresponse = rekognition.get_label_detection(JobId=job_id)\n</code></pre>"},{"location":"aws-services/comprehend-rekognition/#exam-focus-areas","title":"Exam Focus Areas","text":"<p>!!! warning \"Key Topics\" - Comprehend for text analysis and NLP - Rekognition for image/video analysis - Custom models for domain-specific use cases - Content moderation capabilities - Healthcare-specific Comprehend Medical</p>"},{"location":"aws-services/glue/","title":"AWS Glue","text":""},{"location":"aws-services/glue/#overview","title":"Overview","text":"<p>Serverless data integration service for ETL and data cataloging.</p>"},{"location":"aws-services/glue/#components","title":"Components","text":"<pre><code>graph TD\n    A[Data Sources] --&gt; B[Crawlers]\n    B --&gt; C[Data Catalog]\n    C --&gt; D[ETL Jobs]\n    D --&gt; E[Target Data Store]\n\n    F[DataBrew] --&gt; E\n    G[Data Quality] --&gt; C</code></pre>"},{"location":"aws-services/glue/#aws-glue-data-catalog","title":"AWS Glue Data Catalog","text":"<p>Centralized metadata repository.</p> Component Description Databases Logical grouping of tables Tables Metadata definition Partitions Data organization Connections Data source credentials"},{"location":"aws-services/glue/#crawlers","title":"Crawlers","text":"<p>Automatically discover schema.</p> <pre><code>import boto3\n\nglue = boto3.client(\"glue\")\n\nglue.create_crawler(\n    Name=\"my-crawler\",\n    Role=\"AWSGlueServiceRole\",\n    DatabaseName=\"my-database\",\n    Targets={\n        \"S3Targets\": [{\"Path\": \"s3://my-bucket/data/\"}]\n    },\n    Schedule=\"cron(0 0 * * ? *)\"  # Daily\n)\n</code></pre>"},{"location":"aws-services/glue/#etl-jobs","title":"ETL Jobs","text":"<p>Spark-based data transformation.</p> <pre><code># Glue ETL script\nfrom awsglue.context import GlueContext\nfrom pyspark.context import SparkContext\n\nsc = SparkContext()\nglueContext = GlueContext(sc)\n\n# Read from catalog\ndatasource = glueContext.create_dynamic_frame.from_catalog(\n    database=\"my_db\",\n    table_name=\"my_table\"\n)\n\n# Transform\ntransformed = datasource.apply_mapping([\n    (\"old_col\", \"string\", \"new_col\", \"string\")\n])\n\n# Write\nglueContext.write_dynamic_frame.from_options(\n    frame=transformed,\n    connection_type=\"s3\",\n    connection_options={\"path\": \"s3://output/\"},\n    format=\"parquet\"\n)\n</code></pre>"},{"location":"aws-services/glue/#aws-glue-databrew","title":"AWS Glue DataBrew","text":"<p>Visual data preparation.</p> Feature Description Datasets Data sources Projects Interactive preparation Recipes Transformation steps Jobs Execute recipes"},{"location":"aws-services/glue/#aws-glue-data-quality","title":"AWS Glue Data Quality","text":"<p>Automated data quality checks.</p> <pre><code># Data quality rules\nrules = \"\"\"\nRules = [\n    IsComplete \"column_name\",\n    Uniqueness \"id\" &gt; 0.99,\n    ColumnValues \"age\" between 0 and 120\n]\n\"\"\"\n</code></pre>"},{"location":"aws-services/glue/#job-types","title":"Job Types","text":"Type Use Case Spark Large-scale ETL Python Shell Simple scripts Streaming Real-time ETL Ray Distributed Python"},{"location":"aws-services/glue/#exam-focus-areas","title":"Exam Focus Areas","text":"<p>!!! warning \"Key Topics\" - Crawlers for schema discovery - Data Catalog for metadata - ETL jobs for transformation - DataBrew for visual preparation - Data Quality for validation</p>"},{"location":"aws-services/other-ml-services/","title":"Other ML Services","text":"<p>Quick reference for other ML services covered in the exam.</p>"},{"location":"aws-services/other-ml-services/#amazon-lex","title":"Amazon Lex","text":"<p>Conversational AI for chatbots.</p> Component Description Intents User goals Slots Parameters to collect Utterances Example phrases Fulfillment Lambda function"},{"location":"aws-services/other-ml-services/#amazon-polly","title":"Amazon Polly","text":"<p>Text-to-speech service.</p> Feature Description Neural voices Natural-sounding speech SSML Speech markup control Lexicons Custom pronunciations Speech marks Timing metadata"},{"location":"aws-services/other-ml-services/#amazon-transcribe","title":"Amazon Transcribe","text":"<p>Speech-to-text service.</p> Feature Description Real-time Streaming transcription Batch Async processing Medical Healthcare-specific Call Analytics Contact center insights"},{"location":"aws-services/other-ml-services/#amazon-translate","title":"Amazon Translate","text":"<p>Neural machine translation.</p> <pre><code>translate = boto3.client(\"translate\")\n\nresponse = translate.translate_text(\n    Text=\"Hello world\",\n    SourceLanguageCode=\"en\",\n    TargetLanguageCode=\"es\"\n)\n# Returns: \"Hola mundo\"\n</code></pre>"},{"location":"aws-services/other-ml-services/#amazon-textract","title":"Amazon Textract","text":"<p>Document text extraction.</p> Feature Description Text Detection Extract raw text Forms Key-value pairs Tables Structured tables Queries Answer specific questions"},{"location":"aws-services/other-ml-services/#amazon-personalize","title":"Amazon Personalize","text":"<p>Recommendation engine.</p> Component Description Datasets Users, items, interactions Recipes Algorithm types Solutions Trained models Campaigns Real-time recommendations"},{"location":"aws-services/other-ml-services/#amazon-forecast","title":"Amazon Forecast","text":"<p>Time series forecasting.</p> Component Description Dataset Group Related datasets Predictor Trained model Forecast Generated predictions"},{"location":"aws-services/other-ml-services/#amazon-kendra","title":"Amazon Kendra","text":"<p>Enterprise search with ML.</p> Feature Description Data Sources Connectors Index Search index Queries Natural language Relevance Tuning Customize ranking"},{"location":"aws-services/other-ml-services/#amazon-fraud-detector","title":"Amazon Fraud Detector","text":"<p>Fraud detection service.</p> Component Description Event Types Transaction types Models Fraud detection models Rules Business logic Detectors Evaluation endpoints"},{"location":"aws-services/other-ml-services/#amazon-a2i-augmented-ai","title":"Amazon A2I (Augmented AI)","text":"<p>Human review workflows.</p> Component Description Flow Definition Review workflow Human Task UI Review interface Workforce Reviewers"},{"location":"aws-services/other-ml-services/#service-selection-guide","title":"Service Selection Guide","text":"Use Case Service Chatbots Amazon Lex Text-to-speech Amazon Polly Speech-to-text Amazon Transcribe Translation Amazon Translate Document processing Amazon Textract Recommendations Amazon Personalize Forecasting Amazon Forecast Enterprise search Amazon Kendra Fraud detection Amazon Fraud Detector Human review Amazon A2I"},{"location":"aws-services/sagemaker/","title":"Amazon SageMaker","text":""},{"location":"aws-services/sagemaker/#overview","title":"Overview","text":"<p>Fully managed service for building, training, and deploying ML models.</p>"},{"location":"aws-services/sagemaker/#sagemaker-components","title":"SageMaker Components","text":"<pre><code>graph TD\n    A[SageMaker Studio] --&gt; B[Data Preparation]\n    B --&gt; C[Training]\n    C --&gt; D[Model Registry]\n    D --&gt; E[Deployment]\n    E --&gt; F[Monitoring]\n\n    B --&gt; B1[Data Wrangler]\n    B --&gt; B2[Feature Store]\n    B --&gt; B3[Processing]\n\n    C --&gt; C1[Training Jobs]\n    C --&gt; C2[Experiments]\n    C --&gt; C3[Debugger]\n    C --&gt; C4[Automatic Model Tuning]\n\n    E --&gt; E1[Real-time Endpoints]\n    E --&gt; E2[Serverless]\n    E --&gt; E3[Batch Transform]\n\n    F --&gt; F1[Model Monitor]\n    F --&gt; F2[Clarify]</code></pre>"},{"location":"aws-services/sagemaker/#key-features","title":"Key Features","text":"Feature Description Studio Unified IDE for ML Data Wrangler Visual data preparation Feature Store Centralized feature repository Training Managed training infrastructure Experiments Track and compare runs Debugger Debug and profile training Clarify Bias and explainability Model Registry Version and manage models Pipelines MLOps workflows Model Monitor Production monitoring"},{"location":"aws-services/sagemaker/#instance-types","title":"Instance Types","text":"Category Types Use Case General ml.m5.* Balanced workloads Compute ml.c5.* CPU-intensive GPU ml.p3., ml.p4d. Deep learning GPU (inference) ml.g4dn.* Inference Memory ml.r5.* Large datasets"},{"location":"aws-services/sagemaker/#data-channels","title":"Data Channels","text":"Channel Purpose train Training data validation Validation data test Test data model Pre-trained model"},{"location":"aws-services/sagemaker/#training-modes","title":"Training Modes","text":"Mode Description Best For File Download to instance Small/medium data Pipe Stream from S3 Large data FastFile POSIX access Random access"},{"location":"aws-services/sagemaker/#exam-focus-areas","title":"Exam Focus Areas","text":"<p>!!! warning \"Key Topics\" - Training job configuration and instance selection - Built-in algorithms and when to use each - Endpoint types and deployment strategies - Model Monitor for production monitoring - Pipelines for MLOps automation</p>"},{"location":"cheat-sheets/","title":"Cheat Sheets","text":"<p>Quick reference guides for last-minute exam prep.</p>"},{"location":"cheat-sheets/#available-cheat-sheets","title":"Available Cheat Sheets","text":"Cheat Sheet Description Services Comparison When to use which service SageMaker Instance Types Instance selection guide Exam Tips Final prep tips and tricks"},{"location":"cheat-sheets/#quick-facts","title":"Quick Facts","text":""},{"location":"cheat-sheets/#exam-details","title":"Exam Details","text":"<ul> <li>Code: MLA-C01</li> <li>Duration: 170 minutes</li> <li>Questions: 65 (50 scored + 15 unscored)</li> <li>Passing Score: 720/1000</li> </ul>"},{"location":"cheat-sheets/#domain-weights","title":"Domain Weights","text":"Domain Weight Focus Domain 1 28% Data Preparation Domain 2 26% Model Development Domain 3 22% Deployment &amp; Orchestration Domain 4 24% Monitoring &amp; Security"},{"location":"cheat-sheets/#key-numbers-to-remember","title":"Key Numbers to Remember","text":"Item Value Real-time endpoint timeout 60 seconds Async endpoint timeout 15 minutes Real-time payload limit 6 MB Async payload limit 1 GB Serverless memory options 1024-6144 MB Spot training savings Up to 90% Savings Plans savings Up to 64%"},{"location":"cheat-sheets/#core-service-mappings","title":"Core Service Mappings","text":"Task Primary Service ML Training SageMaker GenAI Bedrock ETL Glue Streaming Kinesis Encryption KMS Secret Storage Secrets Manager Monitoring CloudWatch Audit Logging CloudTrail"},{"location":"cheat-sheets/exam-tips/","title":"Exam Tips","text":"<p>Final preparation tips for the MLA-C01 exam.</p>"},{"location":"cheat-sheets/exam-tips/#time-management","title":"Time Management","text":"<ul> <li>170 minutes for 65 questions = ~2.5 minutes per question</li> <li>Flag difficult questions and return later</li> <li>Don't spend more than 4 minutes on any single question</li> <li>Reserve 15 minutes at the end for review</li> </ul>"},{"location":"cheat-sheets/exam-tips/#question-strategy","title":"Question Strategy","text":""},{"location":"cheat-sheets/exam-tips/#read-carefully","title":"Read Carefully","text":"<ul> <li>Look for keywords: MOST, LEAST, BEST, MINIMUM, MAXIMUM</li> <li>Identify the specific requirement (cost, latency, security, etc.)</li> <li>Note any constraints mentioned</li> </ul>"},{"location":"cheat-sheets/exam-tips/#elimination-process","title":"Elimination Process","text":"<ol> <li>Eliminate obviously wrong answers</li> <li>Compare remaining options against requirements</li> <li>Choose the option that BEST fits ALL requirements</li> </ol>"},{"location":"cheat-sheets/exam-tips/#common-traps","title":"Common Traps","text":"<ul> <li>Solutions that work but are overly complex</li> <li>Options that solve a different problem</li> <li>Services that exist but aren't best suited</li> </ul>"},{"location":"cheat-sheets/exam-tips/#key-topics-to-review","title":"Key Topics to Review","text":""},{"location":"cheat-sheets/exam-tips/#sagemaker-heavily-tested","title":"SageMaker (Heavily Tested)","text":"<ul> <li>Training job configuration</li> <li>Endpoint types and selection criteria</li> <li>Built-in algorithms and use cases</li> <li>Pipelines for MLOps</li> <li>Model Monitor for drift detection</li> </ul>"},{"location":"cheat-sheets/exam-tips/#bedrock","title":"Bedrock","text":"<ul> <li>When to use Bedrock vs SageMaker</li> <li>Knowledge Bases for RAG</li> <li>Guardrails for content filtering</li> <li>Fine-tuning capabilities</li> </ul>"},{"location":"cheat-sheets/exam-tips/#data-preparation","title":"Data Preparation","text":"<ul> <li>Glue components (Crawlers, Catalog, ETL)</li> <li>Feature Store (Online vs Offline)</li> <li>Data formats (Parquet, RecordIO)</li> <li>Kinesis for streaming</li> </ul>"},{"location":"cheat-sheets/exam-tips/#security","title":"Security","text":"<ul> <li>IAM roles for SageMaker</li> <li>KMS encryption</li> <li>VPC configuration</li> <li>Secrets Manager</li> </ul>"},{"location":"cheat-sheets/exam-tips/#cost-optimization","title":"Cost Optimization","text":"<ul> <li>Spot Training</li> <li>Serverless endpoints</li> <li>Auto Scaling</li> <li>Instance selection</li> </ul>"},{"location":"cheat-sheets/exam-tips/#common-question-patterns","title":"Common Question Patterns","text":""},{"location":"cheat-sheets/exam-tips/#which-endpoint-type","title":"\"Which endpoint type...\"","text":"<p>Consider:</p> <ul> <li>Latency requirements</li> <li>Payload size</li> <li>Traffic pattern</li> <li>Cost constraints</li> </ul>"},{"location":"cheat-sheets/exam-tips/#which-service-for-data","title":"\"Which service for data...\"","text":"<p>Consider:</p> <ul> <li>Batch vs streaming</li> <li>Transformation complexity</li> <li>Storage requirements</li> <li>Query patterns</li> </ul>"},{"location":"cheat-sheets/exam-tips/#how-to-reduce-costs","title":"\"How to reduce costs...\"","text":"<p>Consider:</p> <ul> <li>Spot instances</li> <li>Serverless options</li> <li>Right-sizing</li> <li>Auto Scaling</li> </ul>"},{"location":"cheat-sheets/exam-tips/#how-to-secure","title":"\"How to secure...\"","text":"<p>Consider:</p> <ul> <li>Encryption (KMS)</li> <li>Access control (IAM)</li> <li>Network isolation (VPC)</li> <li>Audit logging (CloudTrail)</li> </ul>"},{"location":"cheat-sheets/exam-tips/#last-day-checklist","title":"Last Day Checklist","text":""},{"location":"cheat-sheets/exam-tips/#review","title":"Review","text":"<ul> <li> All domain summaries</li> <li> Services comparison chart</li> <li> Instance type guide</li> <li> Practice exam mistakes</li> </ul>"},{"location":"cheat-sheets/exam-tips/#dont-cram","title":"Don't Cram","text":"<ul> <li> Get good sleep</li> <li> Eat a proper meal</li> <li> Arrive early</li> <li> Bring valid ID</li> </ul>"},{"location":"cheat-sheets/exam-tips/#during-exam","title":"During Exam","text":"<ul> <li> Read all options before answering</li> <li> Flag uncertain questions</li> <li> Use all available time</li> <li> Trust your preparation</li> </ul>"},{"location":"cheat-sheets/exam-tips/#key-formulasnumbers","title":"Key Formulas/Numbers","text":"Item Value Passing score 720/1000 Scored questions 50 Unscored questions 15 Real-time endpoint timeout 60 seconds Async endpoint timeout 15 minutes Real-time payload limit 6 MB Async payload limit 1 GB Spot training savings Up to 90%"},{"location":"cheat-sheets/exam-tips/#acronyms-to-know","title":"Acronyms to Know","text":"Acronym Meaning HPO Hyperparameter Optimization AMT Automatic Model Tuning MME Multi-Model Endpoint RAG Retrieval Augmented Generation SHAP SHapley Additive exPlanations CI/CD Continuous Integration/Deployment IAM Identity and Access Management KMS Key Management Service VPC Virtual Private Cloud ECR Elastic Container Registry"},{"location":"cheat-sheets/exam-tips/#good-luck","title":"Good Luck!","text":"<p>Trust your preparation. You've got this!</p>"},{"location":"cheat-sheets/sagemaker-instance-types/","title":"SageMaker Instance Types","text":"<p>Quick reference for choosing the right instance type.</p>"},{"location":"cheat-sheets/sagemaker-instance-types/#instance-categories","title":"Instance Categories","text":""},{"location":"cheat-sheets/sagemaker-instance-types/#general-purpose-mlm5","title":"General Purpose (ml.m5.*)","text":"Instance vCPU Memory Use Case ml.m5.large 2 8 GB Small jobs, testing ml.m5.xlarge 4 16 GB Medium workloads ml.m5.2xlarge 8 32 GB Larger datasets ml.m5.4xlarge 16 64 GB Production training ml.m5.12xlarge 48 192 GB Large-scale <p>Best for: Balanced compute and memory requirements</p>"},{"location":"cheat-sheets/sagemaker-instance-types/#compute-optimized-mlc5","title":"Compute Optimized (ml.c5.*)","text":"Instance vCPU Memory Use Case ml.c5.large 2 4 GB CPU-intensive ml.c5.xlarge 4 8 GB Preprocessing ml.c5.2xlarge 8 16 GB Inference ml.c5.4xlarge 16 32 GB Production <p>Best for: CPU-bound algorithms (tree-based, preprocessing)</p>"},{"location":"cheat-sheets/sagemaker-instance-types/#gpu-instances-mlp3-mlp4d-mlg4dn-mlg5","title":"GPU Instances (ml.p3., ml.p4d., ml.g4dn., ml.g5.)","text":"Instance GPU GPU Memory Use Case ml.g4dn.xlarge 1x T4 16 GB Inference, light training ml.g5.xlarge 1x A10G 24 GB Training/inference ml.p3.2xlarge 1x V100 16 GB Deep learning training ml.p3.8xlarge 4x V100 64 GB Distributed training ml.p3.16xlarge 8x V100 128 GB Large models ml.p4d.24xlarge 8x A100 320 GB Largest models <p>Best for: Deep learning, computer vision, NLP</p>"},{"location":"cheat-sheets/sagemaker-instance-types/#memory-optimized-mlr5","title":"Memory Optimized (ml.r5.*)","text":"Instance vCPU Memory Use Case ml.r5.large 2 16 GB Memory-intensive ml.r5.xlarge 4 32 GB Large datasets ml.r5.2xlarge 8 64 GB In-memory processing ml.r5.4xlarge 16 128 GB Very large datasets <p>Best for: Large datasets that need to fit in memory</p>"},{"location":"cheat-sheets/sagemaker-instance-types/#instance-selection-guide","title":"Instance Selection Guide","text":""},{"location":"cheat-sheets/sagemaker-instance-types/#training","title":"Training","text":"Algorithm Type Recommended XGBoost, linear ml.m5., ml.c5. Deep learning (small) ml.g4dn., ml.g5. Deep learning (large) ml.p3., ml.p4d. Large data processing ml.r5.*"},{"location":"cheat-sheets/sagemaker-instance-types/#inference","title":"Inference","text":"Workload Recommended Low latency, CPU ml.c5.* Low latency, GPU ml.g4dn., ml.g5. Cost-sensitive ml.m5.large, Serverless High throughput ml.c5.* with Auto Scaling"},{"location":"cheat-sheets/sagemaker-instance-types/#cost-optimization-tips","title":"Cost Optimization Tips","text":"Strategy Savings When to Use Spot Training Up to 90% Non-urgent training Savings Plans Up to 64% Consistent usage Serverless Variable Unpredictable traffic Right-sizing Varies Regularly"},{"location":"cheat-sheets/sagemaker-instance-types/#instance-limits","title":"Instance Limits","text":"Limit Type Default Notes ml.p3 instances 1-2 Request increase ml.p4d instances 0 Request increase Total instances Varies Per account"},{"location":"cheat-sheets/sagemaker-instance-types/#quick-decision-tree","title":"Quick Decision Tree","text":"<pre><code>Need GPU?\n\u251c\u2500\u2500 No \u2192 Need more memory than CPU?\n\u2502         \u251c\u2500\u2500 Yes \u2192 ml.r5.*\n\u2502         \u2514\u2500\u2500 No \u2192 CPU-intensive?\n\u2502                   \u251c\u2500\u2500 Yes \u2192 ml.c5.*\n\u2502                   \u2514\u2500\u2500 No \u2192 ml.m5.*\n\u2514\u2500\u2500 Yes \u2192 Training or Inference?\n          \u251c\u2500\u2500 Training \u2192 Model size?\n          \u2502              \u251c\u2500\u2500 Small \u2192 ml.g4dn.*, ml.g5.*\n          \u2502              \u2514\u2500\u2500 Large \u2192 ml.p3.*, ml.p4d.*\n          \u2514\u2500\u2500 Inference \u2192 ml.g4dn.xlarge\n</code></pre>"},{"location":"cheat-sheets/services-comparison/","title":"Services Comparison","text":"<p>Quick reference for choosing the right AWS service.</p>"},{"location":"cheat-sheets/services-comparison/#endpoint-types","title":"Endpoint Types","text":"Type Latency Payload Timeout Cost Model Use Case Real-time Milliseconds 6 MB 60s Per hour Interactive apps Serverless Seconds (cold start) 6 MB 60s Per request Variable traffic Async Minutes 1 GB 15 min Per hour Large payloads Batch Transform Hours - - Per job Offline batch"},{"location":"cheat-sheets/services-comparison/#data-processing-services","title":"Data Processing Services","text":"Service Mode Use Case Scalability Glue ETL Batch Large-scale ETL Auto-scaling Glue DataBrew Batch Visual prep Managed EMR Batch Custom Spark Manual/Auto Kinesis Data Streams Streaming Custom consumers Shards Kinesis Firehose Streaming Direct to S3/etc Automatic SageMaker Processing Batch ML data prep Instance-based"},{"location":"cheat-sheets/services-comparison/#storage-for-ml","title":"Storage for ML","text":"Service Data Type Access Pattern Use Case S3 Any Object access Data lake, models Feature Store Online Features Low-latency Real-time inference Feature Store Offline Features Batch queries Training Redshift Structured SQL queries Analytics DynamoDB Key-value Low-latency Application data"},{"location":"cheat-sheets/services-comparison/#mlops-orchestration","title":"MLOps Orchestration","text":"Service Focus Best For SageMaker Pipelines ML-specific End-to-end ML workflows Step Functions General Multi-service orchestration MWAA (Airflow) General Complex DAGs, existing Airflow EventBridge Events Event-driven triggers"},{"location":"cheat-sheets/services-comparison/#hyperparameter-tuning-strategies","title":"Hyperparameter Tuning Strategies","text":"Strategy Best For Speed Quality Bayesian Most cases Fast High Random Exploration Medium Medium Grid Small space Slow Complete Hyperband Deep learning Fast High"},{"location":"cheat-sheets/services-comparison/#monitoring-services","title":"Monitoring Services","text":"Service Purpose Data Type Model Monitor Drift detection ML metrics CloudWatch Metrics Infrastructure Time series CloudWatch Logs Application logs Text CloudTrail API audit Events X-Ray Distributed tracing Traces"},{"location":"cheat-sheets/services-comparison/#security-services","title":"Security Services","text":"Service Purpose IAM Identity and access KMS Encryption keys Secrets Manager Credentials Macie Sensitive data discovery VPC Network isolation Security Groups Instance firewall"},{"location":"cheat-sheets/services-comparison/#ai-services-vs-custom-ml","title":"AI Services vs Custom ML","text":"Use Case AI Service Custom (SageMaker) Text sentiment Comprehend Custom NLP Object detection Rekognition Custom CV Speech-to-text Transcribe Custom ASR Translation Translate Custom NMT Recommendations Personalize Custom RecSys Forecasting Forecast Custom models"},{"location":"cheat-sheets/services-comparison/#bedrock-vs-sagemaker","title":"Bedrock vs SageMaker","text":"Aspect Bedrock SageMaker Model type Foundation models Any ML model Training Fine-tuning only Full training Infrastructure Serverless Managed instances Customization Limited Full control Use case GenAI apps Custom ML"},{"location":"domain-1-data-preparation/","title":"Domain 1: Data Preparation for Machine Learning","text":"<p>Weight: 28% of scored content</p> <p>This domain covers the foundational skills needed to prepare data for machine learning workloads on AWS.</p>"},{"location":"domain-1-data-preparation/#topics-covered","title":"Topics Covered","text":"Topic Description Data Ingestion S3, Kinesis, Glue, DataSync Data Transformation Glue ETL, DataBrew, EMR, Spark Data Validation Glue Data Quality, data integrity Feature Engineering SageMaker Feature Store, Processing Data Storage Lake Formation, Athena, data formats"},{"location":"domain-1-data-preparation/#key-concepts","title":"Key Concepts","text":""},{"location":"domain-1-data-preparation/#data-ingestion-patterns","title":"Data Ingestion Patterns","text":"<pre><code>graph LR\n    A[Data Sources] --&gt; B{Ingestion Method}\n    B --&gt; C[Batch: S3, Glue]\n    B --&gt; D[Streaming: Kinesis, Firehose]\n    B --&gt; E[On-premises: DataSync]\n    C --&gt; F[Data Lake / S3]\n    D --&gt; F\n    E --&gt; F</code></pre>"},{"location":"domain-1-data-preparation/#common-data-formats-for-ml","title":"Common Data Formats for ML","text":"Format Use Case Pros Parquet Columnar analytics Compression, fast reads CSV Simple tabular data Universal compatibility JSON/JSONL Semi-structured data Flexibility RecordIO SageMaker training Optimized for streaming TFRecord TensorFlow training TensorFlow native"},{"location":"domain-1-data-preparation/#study-checklist","title":"Study Checklist","text":"<ul> <li> Understand S3 storage classes and lifecycle policies</li> <li> Know Glue components: Crawlers, Data Catalog, Jobs</li> <li> Understand Kinesis Data Streams vs Data Firehose</li> <li> Know SageMaker Feature Store online vs offline</li> <li> Understand data validation and quality checks</li> </ul>"},{"location":"domain-1-data-preparation/data-ingestion/","title":"Data Ingestion","text":""},{"location":"domain-1-data-preparation/data-ingestion/#overview","title":"Overview","text":"<p>Data ingestion is the process of moving data from various sources into AWS for ML workloads.</p>"},{"location":"domain-1-data-preparation/data-ingestion/#key-services","title":"Key Services","text":""},{"location":"domain-1-data-preparation/data-ingestion/#amazon-s3","title":"Amazon S3","text":"<p>Primary storage for ML data. Key concepts:</p> <ul> <li>Storage classes: Standard, Intelligent-Tiering, Glacier</li> <li>Versioning for data lineage</li> <li>S3 Select for querying data in place</li> <li>Transfer Acceleration for faster uploads</li> </ul>"},{"location":"domain-1-data-preparation/data-ingestion/#amazon-kinesis","title":"Amazon Kinesis","text":"<p>Real-time streaming data ingestion.</p> Service Use Case Kinesis Data Streams Custom real-time processing Kinesis Data Firehose Managed delivery to S3/Redshift Kinesis Data Analytics SQL on streaming data"},{"location":"domain-1-data-preparation/data-ingestion/#aws-glue","title":"AWS Glue","text":"<p>Serverless ETL and data cataloging.</p> <ul> <li>Crawlers: Automatically discover schema</li> <li>Data Catalog: Centralized metadata repository</li> <li>ETL Jobs: Transform data with Spark</li> </ul>"},{"location":"domain-1-data-preparation/data-ingestion/#aws-datasync","title":"AWS DataSync","text":"<p>Automated data transfer from on-premises to AWS.</p>"},{"location":"domain-1-data-preparation/data-ingestion/#best-practices","title":"Best Practices","text":"<p>Data Organization</p> <p>Use a consistent folder structure in S3: <code>s3://bucket/     \u251c\u2500\u2500 raw/              # Original data     \u251c\u2500\u2500 processed/        # Cleaned data     \u251c\u2500\u2500 features/         # Feature store data     \u2514\u2500\u2500 models/           # Trained models</code></p>"},{"location":"domain-1-data-preparation/data-ingestion/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Common Exam Scenarios\" - Streaming data \u2192 Kinesis Data Firehose to S3 - On-premises large datasets \u2192 DataSync - Schema discovery \u2192 Glue Crawlers - Cross-region replication \u2192 S3 Replication</p>"},{"location":"domain-1-data-preparation/data-storage/","title":"Data Storage","text":""},{"location":"domain-1-data-preparation/data-storage/#overview","title":"Overview","text":"<p>Choosing the right storage solutions for ML data.</p>"},{"location":"domain-1-data-preparation/data-storage/#amazon-s3","title":"Amazon S3","text":"<p>Primary data lake storage for ML.</p>"},{"location":"domain-1-data-preparation/data-storage/#storage-classes","title":"Storage Classes","text":"Class Use Case Retrieval Standard Frequent access Immediate Intelligent-Tiering Unknown access patterns Automatic Standard-IA Infrequent access Immediate Glacier Archive Minutes to hours Glacier Deep Archive Long-term archive Hours"},{"location":"domain-1-data-preparation/data-storage/#s3-for-ml-best-practices","title":"S3 for ML Best Practices","text":"<ul> <li>Use Parquet/ORC for columnar analytics</li> <li>Enable versioning for data lineage</li> <li>Use S3 Select for filtering at source</li> <li>Configure lifecycle policies for cost optimization</li> </ul>"},{"location":"domain-1-data-preparation/data-storage/#aws-lake-formation","title":"AWS Lake Formation","text":"<p>Centralized data lake management.</p>"},{"location":"domain-1-data-preparation/data-storage/#key-features","title":"Key Features","text":"<ul> <li>Fine-grained access control</li> <li>Data sharing across accounts</li> <li>Built-in data catalog integration</li> <li>Row/column-level security</li> </ul> <pre><code># Grant permissions\nlake_formation.grant_permissions(\n    Principal={'DataLakePrincipalIdentifier': 'arn:aws:iam::account:role/role'},\n    Resource={'Table': {'DatabaseName': 'db', 'Name': 'table'}},\n    Permissions=['SELECT']\n)\n</code></pre>"},{"location":"domain-1-data-preparation/data-storage/#amazon-athena","title":"Amazon Athena","text":"<p>Serverless SQL queries on S3 data.</p> <pre><code>-- Query data directly in S3\nSELECT customer_id, COUNT(*) as order_count\nFROM orders\nWHERE order_date &gt;= '2024-01-01'\nGROUP BY customer_id\n</code></pre>"},{"location":"domain-1-data-preparation/data-storage/#athena-for-ml","title":"Athena for ML","text":"<ul> <li>Query training data without loading into memory</li> <li>Create datasets from complex joins</li> <li>Partition data for efficient queries</li> </ul>"},{"location":"domain-1-data-preparation/data-storage/#data-formats-comparison","title":"Data Formats Comparison","text":"Format Best For Compression Schema Parquet Analytics, columnar High Embedded CSV Simple data Low External JSON Semi-structured Medium Flexible Avro Streaming Medium Embedded RecordIO SageMaker Medium External"},{"location":"domain-1-data-preparation/data-storage/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Storage Decisions\" - S3 + Athena for ad-hoc queries - Lake Formation for governed data access - Parquet for most ML workloads - RecordIO for large-scale SageMaker training</p>"},{"location":"domain-1-data-preparation/data-transformation/","title":"Data Transformation","text":""},{"location":"domain-1-data-preparation/data-transformation/#overview","title":"Overview","text":"<p>Transforming raw data into formats suitable for ML model training.</p>"},{"location":"domain-1-data-preparation/data-transformation/#key-services","title":"Key Services","text":""},{"location":"domain-1-data-preparation/data-transformation/#aws-glue-etl","title":"AWS Glue ETL","text":"<p>Serverless Apache Spark for data transformation.</p> <pre><code># Example Glue ETL script\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom awsglue.context import GlueContext\nfrom pyspark.context import SparkContext\n\nsc = SparkContext()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\n\n# Read from Data Catalog\ndatasource = glueContext.create_dynamic_frame.from_catalog(\n    database=\"mydb\",\n    table_name=\"mytable\"\n)\n\n# Apply transformations\ntransformed = ApplyMapping.apply(\n    frame=datasource,\n    mappings=[\n        (\"old_col\", \"string\", \"new_col\", \"string\"),\n    ]\n)\n\n# Write to S3\nglueContext.write_dynamic_frame.from_options(\n    frame=transformed,\n    connection_type=\"s3\",\n    connection_options={\"path\": \"s3://bucket/output/\"},\n    format=\"parquet\"\n)\n</code></pre>"},{"location":"domain-1-data-preparation/data-transformation/#aws-glue-databrew","title":"AWS Glue DataBrew","text":"<p>Visual data preparation tool for non-coders.</p> <ul> <li>250+ built-in transformations</li> <li>Profile data quality</li> <li>Recipe-based transformations</li> </ul>"},{"location":"domain-1-data-preparation/data-transformation/#amazon-emr","title":"Amazon EMR","text":"<p>Managed Hadoop/Spark for large-scale processing.</p> Use Case When to Use Glue Serverless, simple ETL EMR Complex processing, custom libraries DataBrew Visual, no-code preparation"},{"location":"domain-1-data-preparation/data-transformation/#sagemaker-processing","title":"SageMaker Processing","text":"<p>Run data processing jobs with custom containers.</p> <pre><code>from sagemaker.processing import ScriptProcessor\n\nprocessor = ScriptProcessor(\n    role=role,\n    image_uri=image_uri,\n    instance_count=1,\n    instance_type=\"ml.m5.xlarge\"\n)\n\nprocessor.run(\n    code=\"preprocessing.py\",\n    inputs=[ProcessingInput(source=\"s3://input/\", destination=\"/opt/ml/processing/input\")],\n    outputs=[ProcessingOutput(source=\"/opt/ml/processing/output\", destination=\"s3://output/\")]\n)\n</code></pre>"},{"location":"domain-1-data-preparation/data-transformation/#common-transformations","title":"Common Transformations","text":"<ul> <li>Handling missing values</li> <li>Encoding categorical variables (one-hot, label encoding)</li> <li>Feature scaling (normalization, standardization)</li> <li>Text tokenization and vectorization</li> <li>Image resizing and augmentation</li> </ul>"},{"location":"domain-1-data-preparation/data-validation/","title":"Data Validation","text":""},{"location":"domain-1-data-preparation/data-validation/#overview","title":"Overview","text":"<p>Ensuring data quality and integrity before ML training.</p>"},{"location":"domain-1-data-preparation/data-validation/#aws-glue-data-quality","title":"AWS Glue Data Quality","text":"<p>Built-in data quality rules in AWS Glue.</p>"},{"location":"domain-1-data-preparation/data-validation/#rule-types","title":"Rule Types","text":"Rule Type Example Completeness Column has no null values Uniqueness Column values are unique Validity Values match expected pattern Consistency Cross-column validation"},{"location":"domain-1-data-preparation/data-validation/#example-rules","title":"Example Rules","text":"<pre><code># Glue Data Quality ruleset\nrules = \"\"\"\nRules = [\n    ColumnExists \"customer_id\",\n    IsComplete \"customer_id\",\n    Uniqueness \"customer_id\" &gt; 0.99,\n    ColumnValues \"age\" between 0 and 120,\n    ColumnLength \"email\" &gt; 5\n]\n\"\"\"\n</code></pre>"},{"location":"domain-1-data-preparation/data-validation/#sagemaker-data-wrangler","title":"SageMaker Data Wrangler","text":"<p>Visual data preparation with built-in quality checks.</p> <ul> <li>Data profiling and visualization</li> <li>Anomaly detection</li> <li>Custom validation rules</li> <li>Export to SageMaker pipelines</li> </ul>"},{"location":"domain-1-data-preparation/data-validation/#best-practices","title":"Best Practices","text":"<p>!!! tip \"Data Quality Checklist\" 1. Check for missing values and decide handling strategy 2. Validate data types match expectations 3. Check for outliers and anomalies 4. Verify data distributions are as expected 5. Ensure target variable is balanced (if classification)</p>"},{"location":"domain-1-data-preparation/data-validation/#schema-validation","title":"Schema Validation","text":"<p>Use AWS Glue Schema Registry for schema enforcement.</p> <pre><code># Register schema\nfrom aws_glue_schema_registry import GlueSchemaRegistrySerializer\n\nserializer = GlueSchemaRegistrySerializer(\n    registry_name=\"my-registry\",\n    schema_name=\"my-schema\"\n)\n</code></pre>"},{"location":"domain-1-data-preparation/data-validation/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Use Glue Data Quality for automated rule-based validation - SageMaker Data Wrangler for visual exploration and validation - Schema Registry for schema evolution and validation</p>"},{"location":"domain-1-data-preparation/feature-engineering/","title":"Feature Engineering","text":""},{"location":"domain-1-data-preparation/feature-engineering/#overview","title":"Overview","text":"<p>Creating and managing features for ML models.</p>"},{"location":"domain-1-data-preparation/feature-engineering/#sagemaker-feature-store","title":"SageMaker Feature Store","text":"<p>Centralized repository for ML features.</p>"},{"location":"domain-1-data-preparation/feature-engineering/#store-types","title":"Store Types","text":"Type Use Case Latency Online Store Real-time inference Milliseconds Offline Store Batch training Minutes"},{"location":"domain-1-data-preparation/feature-engineering/#creating-a-feature-group","title":"Creating a Feature Group","text":"<pre><code>from sagemaker.feature_store.feature_group import FeatureGroup\n\nfeature_group = FeatureGroup(\n    name=\"customer-features\",\n    sagemaker_session=sagemaker_session,\n    feature_definitions=[\n        FeatureDefinition(feature_name=\"customer_id\", feature_type=FeatureTypeEnum.STRING),\n        FeatureDefinition(feature_name=\"age\", feature_type=FeatureTypeEnum.INTEGRAL),\n        FeatureDefinition(feature_name=\"total_purchases\", feature_type=FeatureTypeEnum.FRACTIONAL),\n    ]\n)\n\nfeature_group.create(\n    s3_uri=\"s3://bucket/feature-store/\",\n    record_identifier_name=\"customer_id\",\n    event_time_feature_name=\"event_time\",\n    role_arn=role,\n    enable_online_store=True\n)\n</code></pre>"},{"location":"domain-1-data-preparation/feature-engineering/#ingesting-features","title":"Ingesting Features","text":"<pre><code># Ingest records\nfeature_group.ingest(data_frame=df, max_workers=3)\n</code></pre>"},{"location":"domain-1-data-preparation/feature-engineering/#retrieving-features","title":"Retrieving Features","text":"<pre><code># Online store - real-time\nrecord = feature_group.get_record(record_identifier_value_as_string=\"customer_123\")\n\n# Offline store - batch\nquery = feature_group.athena_query()\nquery.run(query_string=\"SELECT * FROM customer_features\", output_location=\"s3://bucket/query-results/\")\ndf = query.as_dataframe()\n</code></pre>"},{"location":"domain-1-data-preparation/feature-engineering/#common-feature-engineering-techniques","title":"Common Feature Engineering Techniques","text":""},{"location":"domain-1-data-preparation/feature-engineering/#numerical-features","title":"Numerical Features","text":"<ul> <li>Normalization (min-max scaling)</li> <li>Standardization (z-score)</li> <li>Log transformation</li> <li>Binning/discretization</li> </ul>"},{"location":"domain-1-data-preparation/feature-engineering/#categorical-features","title":"Categorical Features","text":"<ul> <li>One-hot encoding</li> <li>Label encoding</li> <li>Target encoding</li> <li>Embedding (for high cardinality)</li> </ul>"},{"location":"domain-1-data-preparation/feature-engineering/#text-features","title":"Text Features","text":"<ul> <li>TF-IDF</li> <li>Word embeddings (Word2Vec, BERT)</li> <li>N-grams</li> </ul>"},{"location":"domain-1-data-preparation/feature-engineering/#time-series-features","title":"Time Series Features","text":"<ul> <li>Lag features</li> <li>Rolling statistics</li> <li>Seasonal decomposition</li> </ul>"},{"location":"domain-1-data-preparation/feature-engineering/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Feature Store Key Points\" - Online store for low-latency inference - Offline store for training data - Feature groups organize related features - Point-in-time queries prevent data leakage</p>"},{"location":"domain-2-model-development/","title":"Domain 2: ML Model Development","text":"<p>Weight: 26% of scored content</p> <p>This domain covers model selection, training, hyperparameter tuning, evaluation, and versioning.</p>"},{"location":"domain-2-model-development/#topics-covered","title":"Topics Covered","text":"Topic Description SageMaker Training Training jobs, instance types, distributed training Built-in Algorithms XGBoost, Linear Learner, etc. Hyperparameter Tuning Automatic model tuning Model Evaluation Metrics, SageMaker Clarify Model Versioning Model Registry Amazon Bedrock Foundation models"},{"location":"domain-2-model-development/#key-concepts","title":"Key Concepts","text":""},{"location":"domain-2-model-development/#sagemaker-training-workflow","title":"SageMaker Training Workflow","text":"<pre><code>graph LR\n    A[Training Data in S3] --&gt; B[Training Job]\n    B --&gt; C[Model Artifacts]\n    C --&gt; D[Model Registry]\n    D --&gt; E[Deployment]</code></pre>"},{"location":"domain-2-model-development/#choosing-the-right-algorithm","title":"Choosing the Right Algorithm","text":"Problem Type Built-in Algorithms Classification XGBoost, Linear Learner, KNN Regression XGBoost, Linear Learner Clustering K-Means Anomaly Detection Random Cut Forest NLP BlazingText, Seq2Seq Computer Vision Image Classification, Object Detection Recommendations Factorization Machines"},{"location":"domain-2-model-development/#study-checklist","title":"Study Checklist","text":"<ul> <li> Understand SageMaker training job configuration</li> <li> Know built-in algorithms and their use cases</li> <li> Understand hyperparameter tuning strategies</li> <li> Know evaluation metrics for different problem types</li> <li> Understand Model Registry for versioning</li> <li> Know when to use Bedrock vs custom training</li> </ul>"},{"location":"domain-2-model-development/amazon-bedrock/","title":"Amazon Bedrock","text":""},{"location":"domain-2-model-development/amazon-bedrock/#overview","title":"Overview","text":"<p>Fully managed service for foundation models (FMs).</p>"},{"location":"domain-2-model-development/amazon-bedrock/#key-concepts","title":"Key Concepts","text":"Concept Description Foundation Model Large pre-trained model Fine-tuning Customize FM with your data Guardrails Content filtering and safety Knowledge Bases RAG with your data Agents Automated task execution"},{"location":"domain-2-model-development/amazon-bedrock/#available-models","title":"Available Models","text":"Provider Models Amazon Titan Text, Titan Embeddings, Titan Image Anthropic Claude 3 family Meta Llama 3 family Cohere Command, Embed Stability AI Stable Diffusion Mistral Mistral, Mixtral"},{"location":"domain-2-model-development/amazon-bedrock/#using-bedrock","title":"Using Bedrock","text":""},{"location":"domain-2-model-development/amazon-bedrock/#text-generation","title":"Text Generation","text":"<pre><code>import boto3\nimport json\n\nbedrock = boto3.client(\"bedrock-runtime\")\n\nresponse = bedrock.invoke_model(\n    modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n    contentType=\"application/json\",\n    accept=\"application/json\",\n    body=json.dumps({\n        \"anthropic_version\": \"bedrock-2023-05-31\",\n        \"max_tokens\": 1000,\n        \"messages\": [\n            {\"role\": \"user\", \"content\": \"Explain machine learning in simple terms.\"}\n        ]\n    })\n)\n\nresult = json.loads(response[\"body\"].read())\n</code></pre>"},{"location":"domain-2-model-development/amazon-bedrock/#embeddings","title":"Embeddings","text":"<pre><code>response = bedrock.invoke_model(\n    modelId=\"amazon.titan-embed-text-v1\",\n    contentType=\"application/json\",\n    accept=\"application/json\",\n    body=json.dumps({\n        \"inputText\": \"Sample text for embedding\"\n    })\n)\n</code></pre>"},{"location":"domain-2-model-development/amazon-bedrock/#fine-tuning","title":"Fine-tuning","text":"<p>Customize models with your data.</p> <pre><code>bedrock = boto3.client(\"bedrock\")\n\nresponse = bedrock.create_model_customization_job(\n    jobName=\"my-fine-tuning-job\",\n    customModelName=\"my-custom-model\",\n    roleArn=role_arn,\n    baseModelIdentifier=\"amazon.titan-text-express-v1\",\n    trainingDataConfig={\n        \"s3Uri\": \"s3://bucket/training-data/\"\n    },\n    outputDataConfig={\n        \"s3Uri\": \"s3://bucket/output/\"\n    },\n    hyperParameters={\n        \"epochCount\": \"3\",\n        \"batchSize\": \"8\",\n        \"learningRate\": \"0.00001\"\n    }\n)\n</code></pre>"},{"location":"domain-2-model-development/amazon-bedrock/#guardrails","title":"Guardrails","text":"<p>Content moderation and filtering.</p> <ul> <li>Denied topics</li> <li>Content filters (hate, violence, etc.)</li> <li>Word filters</li> <li>PII detection and masking</li> </ul>"},{"location":"domain-2-model-development/amazon-bedrock/#knowledge-bases-rag","title":"Knowledge Bases (RAG)","text":"<p>Augment models with your data.</p> <pre><code>graph LR\n    A[User Query] --&gt; B[Embedding]\n    B --&gt; C[Vector Search]\n    C --&gt; D[Retrieved Context]\n    D --&gt; E[FM + Context]\n    E --&gt; F[Response]</code></pre>"},{"location":"domain-2-model-development/amazon-bedrock/#agents","title":"Agents","text":"<p>Automate multi-step tasks.</p> <ul> <li>Define actions via Lambda functions</li> <li>Access knowledge bases</li> <li>Orchestrate complex workflows</li> </ul>"},{"location":"domain-2-model-development/amazon-bedrock/#sagemaker-vs-bedrock","title":"SageMaker vs Bedrock","text":"Feature SageMaker Bedrock Custom Training Yes Limited (fine-tuning) Foundation Models Via JumpStart Native Infrastructure Managed Serverless Use Case Custom ML GenAI applications"},{"location":"domain-2-model-development/amazon-bedrock/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Bedrock is serverless, no infrastructure management - Use fine-tuning for domain-specific customization - Guardrails for content safety - Knowledge Bases for RAG patterns - Agents for complex task automation</p>"},{"location":"domain-2-model-development/built-in-algorithms/","title":"Built-in Algorithms","text":""},{"location":"domain-2-model-development/built-in-algorithms/#overview","title":"Overview","text":"<p>SageMaker provides optimized built-in algorithms for common ML tasks.</p>"},{"location":"domain-2-model-development/built-in-algorithms/#supervised-learning","title":"Supervised Learning","text":""},{"location":"domain-2-model-development/built-in-algorithms/#xgboost","title":"XGBoost","text":"<p>Gradient boosting for classification and regression.</p> Parameter Description num_round Number of boosting rounds max_depth Maximum tree depth eta Learning rate objective Loss function <pre><code>from sagemaker import image_uris\n\nxgb_image = image_uris.retrieve(\"xgboost\", region, version=\"1.5-1\")\n\nxgb = Estimator(\n    image_uri=xgb_image,\n    role=role,\n    instance_count=1,\n    instance_type=\"ml.m5.xlarge\",\n    hyperparameters={\n        \"objective\": \"binary:logistic\",\n        \"num_round\": 100,\n        \"max_depth\": 5\n    }\n)\n</code></pre>"},{"location":"domain-2-model-development/built-in-algorithms/#linear-learner","title":"Linear Learner","text":"<p>Linear models for classification and regression.</p> <ul> <li>Supports L1/L2 regularization</li> <li>Automatic model tuning</li> <li>Built-in normalization</li> </ul>"},{"location":"domain-2-model-development/built-in-algorithms/#k-nearest-neighbors-knn","title":"K-Nearest Neighbors (KNN)","text":"<p>Classification and regression based on similarity.</p> <ul> <li>Supports different distance metrics</li> <li>Index-based for fast inference</li> <li>Good for recommendation systems</li> </ul>"},{"location":"domain-2-model-development/built-in-algorithms/#unsupervised-learning","title":"Unsupervised Learning","text":""},{"location":"domain-2-model-development/built-in-algorithms/#k-means","title":"K-Means","text":"<p>Clustering algorithm.</p> Parameter Description k Number of clusters init_method Initialization (random, kmeans++)"},{"location":"domain-2-model-development/built-in-algorithms/#principal-component-analysis-pca","title":"Principal Component Analysis (PCA)","text":"<p>Dimensionality reduction.</p> <ul> <li>Regular mode: covariance matrix</li> <li>Randomized mode: for large datasets</li> </ul>"},{"location":"domain-2-model-development/built-in-algorithms/#random-cut-forest","title":"Random Cut Forest","text":"<p>Anomaly detection.</p> <ul> <li>Unsupervised anomaly scoring</li> <li>Real-time and batch inference</li> </ul>"},{"location":"domain-2-model-development/built-in-algorithms/#computer-vision","title":"Computer Vision","text":""},{"location":"domain-2-model-development/built-in-algorithms/#image-classification","title":"Image Classification","text":"<p>CNN-based image classification.</p> <ul> <li>Transfer learning with pretrained models</li> <li>Multi-GPU training support</li> </ul>"},{"location":"domain-2-model-development/built-in-algorithms/#object-detection","title":"Object Detection","text":"<p>Detect objects and bounding boxes.</p> <ul> <li>SSD (Single Shot Detector)</li> <li>Faster R-CNN</li> </ul>"},{"location":"domain-2-model-development/built-in-algorithms/#semantic-segmentation","title":"Semantic Segmentation","text":"<p>Pixel-level classification.</p> <ul> <li>FCN (Fully Convolutional Network)</li> <li>PSP (Pyramid Scene Parsing)</li> </ul>"},{"location":"domain-2-model-development/built-in-algorithms/#nlp","title":"NLP","text":""},{"location":"domain-2-model-development/built-in-algorithms/#blazingtext","title":"BlazingText","text":"<p>Word embeddings and text classification.</p> Mode Use Case Word2Vec Word embeddings Text Classification Supervised classification"},{"location":"domain-2-model-development/built-in-algorithms/#sequence-to-sequence","title":"Sequence-to-Sequence","text":"<p>Encoder-decoder for translation, summarization.</p>"},{"location":"domain-2-model-development/built-in-algorithms/#algorithm-selection-guide","title":"Algorithm Selection Guide","text":"<pre><code>graph TD\n    A[Problem Type] --&gt; B{Supervised?}\n    B --&gt;|Yes| C{Target Type}\n    B --&gt;|No| D{Goal}\n    C --&gt;|Continuous| E[XGBoost, Linear Learner]\n    C --&gt;|Categorical| F[XGBoost, Linear Learner, KNN]\n    D --&gt;|Clustering| G[K-Means]\n    D --&gt;|Anomaly| H[Random Cut Forest]\n    D --&gt;|Dimensionality| I[PCA]</code></pre>"},{"location":"domain-2-model-development/built-in-algorithms/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Algorithm Selection\" - XGBoost: Most versatile, start here for tabular data - Linear Learner: Sparse data, need interpretability - Random Cut Forest: Streaming anomaly detection - BlazingText: Fast text classification</p>"},{"location":"domain-2-model-development/hyperparameter-tuning/","title":"Hyperparameter Tuning","text":""},{"location":"domain-2-model-development/hyperparameter-tuning/#overview","title":"Overview","text":"<p>Automatic Model Tuning (AMT) in SageMaker finds optimal hyperparameters.</p>"},{"location":"domain-2-model-development/hyperparameter-tuning/#tuning-strategies","title":"Tuning Strategies","text":"Strategy Description Best For Bayesian Probabilistic model of objective Most use cases Random Random sampling Exploration Grid Exhaustive search Small search space Hyperband Early stopping of poor performers Large search space"},{"location":"domain-2-model-development/hyperparameter-tuning/#creating-a-tuning-job","title":"Creating a Tuning Job","text":"<pre><code>from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter\n\nhyperparameter_ranges = {\n    \"learning_rate\": ContinuousParameter(0.001, 0.1),\n    \"num_layers\": IntegerParameter(2, 10),\n    \"dropout\": ContinuousParameter(0.1, 0.5)\n}\n\ntuner = HyperparameterTuner(\n    estimator=estimator,\n    objective_metric_name=\"validation:accuracy\",\n    hyperparameter_ranges=hyperparameter_ranges,\n    max_jobs=20,\n    max_parallel_jobs=4,\n    strategy=\"Bayesian\"\n)\n\ntuner.fit({\"train\": train_data, \"validation\": val_data})\n</code></pre>"},{"location":"domain-2-model-development/hyperparameter-tuning/#parameter-types","title":"Parameter Types","text":"Type Example Use Case ContinuousParameter Learning rate, dropout Floating point values IntegerParameter Layers, neurons Whole numbers CategoricalParameter Optimizer type Discrete choices"},{"location":"domain-2-model-development/hyperparameter-tuning/#warm-start","title":"Warm Start","text":"<p>Resume tuning from previous jobs.</p> <pre><code>from sagemaker.tuner import WarmStartConfig, WarmStartTypes\n\nwarm_start_config = WarmStartConfig(\n    warm_start_type=WarmStartTypes.TRANSFER_LEARNING,\n    parents=[\"previous-tuning-job-name\"]\n)\n\ntuner = HyperparameterTuner(\n    ...\n    warm_start_config=warm_start_config\n)\n</code></pre>"},{"location":"domain-2-model-development/hyperparameter-tuning/#best-practices","title":"Best Practices","text":"<p>!!! tip \"Tuning Tips\" 1. Start with a wide search range 2. Use Bayesian for efficiency 3. Enable early stopping to save costs 4. Use warm start for iterative refinement</p>"},{"location":"domain-2-model-development/hyperparameter-tuning/#objective-metrics","title":"Objective Metrics","text":"<p>Common metrics to optimize:</p> Problem Metric Direction Classification accuracy, f1, auc Maximize Regression mse, rmse, mae Minimize Ranking ndcg Maximize"},{"location":"domain-2-model-development/hyperparameter-tuning/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Bayesian is most efficient for most cases - Hyperband good for deep learning with early stopping - Warm start saves time when refining previous tuning - Set max_parallel_jobs based on budget and urgency</p>"},{"location":"domain-2-model-development/model-evaluation/","title":"Model Evaluation","text":""},{"location":"domain-2-model-development/model-evaluation/#overview","title":"Overview","text":"<p>Evaluating model performance and detecting bias.</p>"},{"location":"domain-2-model-development/model-evaluation/#classification-metrics","title":"Classification Metrics","text":"Metric Formula Use When Accuracy (TP+TN)/(TP+TN+FP+FN) Balanced classes Precision TP/(TP+FP) False positives costly Recall TP/(TP+FN) False negatives costly F1 Score 2(PR)/(P+R) Balance precision/recall AUC-ROC Area under ROC curve Ranking ability"},{"location":"domain-2-model-development/model-evaluation/#regression-metrics","title":"Regression Metrics","text":"Metric Description MSE Mean Squared Error RMSE Root Mean Squared Error MAE Mean Absolute Error R\u00b2 Coefficient of determination MAPE Mean Absolute Percentage Error"},{"location":"domain-2-model-development/model-evaluation/#sagemaker-clarify","title":"SageMaker Clarify","text":"<p>Detect bias and explain predictions.</p>"},{"location":"domain-2-model-development/model-evaluation/#bias-detection","title":"Bias Detection","text":"<pre><code>from sagemaker.clarify import SageMakerClarifyProcessor, BiasConfig, DataConfig\n\nclarify_processor = SageMakerClarifyProcessor(\n    role=role,\n    instance_count=1,\n    instance_type=\"ml.m5.xlarge\"\n)\n\nbias_config = BiasConfig(\n    label_values_or_threshold=[1],\n    facet_name=\"gender\",\n    facet_values_or_threshold=[0]\n)\n\ndata_config = DataConfig(\n    s3_data_input_path=\"s3://bucket/data/\",\n    s3_output_path=\"s3://bucket/clarify-output/\",\n    label=\"target\",\n    headers=[\"feature1\", \"feature2\", \"target\"]\n)\n\nclarify_processor.run_bias(\n    data_config=data_config,\n    bias_config=bias_config,\n    pre_training_methods=\"all\",\n    post_training_methods=\"all\"\n)\n</code></pre>"},{"location":"domain-2-model-development/model-evaluation/#bias-metrics","title":"Bias Metrics","text":"Metric Description Class Imbalance (CI) Difference in class proportions Difference in Proportions (DPL) Label distribution difference Disparate Impact (DI) Ratio of positive outcomes"},{"location":"domain-2-model-development/model-evaluation/#model-explainability","title":"Model Explainability","text":"<p>SHAP (SHapley Additive exPlanations) values.</p> <pre><code>from sagemaker.clarify import ModelConfig, SHAPConfig\n\nmodel_config = ModelConfig(\n    model_name=\"my-model\",\n    instance_type=\"ml.m5.xlarge\",\n    instance_count=1\n)\n\nshap_config = SHAPConfig(\n    baseline=[baseline_data],\n    num_samples=100,\n    agg_method=\"mean_abs\"\n)\n\nclarify_processor.run_explainability(\n    data_config=data_config,\n    model_config=model_config,\n    explainability_config=shap_config\n)\n</code></pre>"},{"location":"domain-2-model-development/model-evaluation/#sagemaker-debugger","title":"SageMaker Debugger","text":"<p>Monitor training in real-time.</p> <ul> <li>Capture tensors during training</li> <li>Built-in rules for common issues</li> <li>Profiling for performance bottlenecks</li> </ul>"},{"location":"domain-2-model-development/model-evaluation/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Use Clarify for bias detection and explainability - SHAP values explain individual predictions - Debugger monitors training for issues - Choose metrics based on business requirements</p>"},{"location":"domain-2-model-development/model-versioning/","title":"Model Versioning","text":""},{"location":"domain-2-model-development/model-versioning/#overview","title":"Overview","text":"<p>Managing model versions with SageMaker Model Registry.</p>"},{"location":"domain-2-model-development/model-versioning/#model-registry","title":"Model Registry","text":"<p>Centralized repository for model versioning.</p>"},{"location":"domain-2-model-development/model-versioning/#key-concepts","title":"Key Concepts","text":"Concept Description Model Package Group Collection of model versions Model Package Single model version Approval Status Pending, Approved, Rejected Model Metrics Performance metrics"},{"location":"domain-2-model-development/model-versioning/#creating-a-model-package-group","title":"Creating a Model Package Group","text":"<pre><code>import boto3\n\nsm_client = boto3.client(\"sagemaker\")\n\nsm_client.create_model_package_group(\n    ModelPackageGroupName=\"my-model-group\",\n    ModelPackageGroupDescription=\"Production models for customer churn\"\n)\n</code></pre>"},{"location":"domain-2-model-development/model-versioning/#registering-a-model","title":"Registering a Model","text":"<pre><code>from sagemaker.model import Model\n\nmodel = Model(\n    image_uri=inference_image,\n    model_data=\"s3://bucket/model.tar.gz\",\n    role=role\n)\n\nmodel_package = model.register(\n    model_package_group_name=\"my-model-group\",\n    content_types=[\"application/json\"],\n    response_types=[\"application/json\"],\n    inference_instances=[\"ml.m5.large\"],\n    transform_instances=[\"ml.m5.large\"],\n    approval_status=\"PendingManualApproval\",\n    model_metrics={\n        \"ModelQuality\": {\n            \"Statistics\": {\n                \"ContentType\": \"application/json\",\n                \"S3Uri\": \"s3://bucket/metrics.json\"\n            }\n        }\n    }\n)\n</code></pre>"},{"location":"domain-2-model-development/model-versioning/#approval-workflow","title":"Approval Workflow","text":"<pre><code># Approve a model\nsm_client.update_model_package(\n    ModelPackageArn=model_package_arn,\n    ModelApprovalStatus=\"Approved\"\n)\n\n# Reject a model\nsm_client.update_model_package(\n    ModelPackageArn=model_package_arn,\n    ModelApprovalStatus=\"Rejected\"\n)\n</code></pre>"},{"location":"domain-2-model-development/model-versioning/#model-lineage","title":"Model Lineage","text":"<p>Track the complete lifecycle of a model.</p> <pre><code>from sagemaker.lineage.context import Context\nfrom sagemaker.lineage.artifact import Artifact\n\n# Query lineage\nartifacts = Artifact.list(source_uri=\"s3://bucket/model.tar.gz\")\n</code></pre>"},{"location":"domain-2-model-development/model-versioning/#sagemaker-experiments","title":"SageMaker Experiments","text":"<p>Track experiments and compare results.</p> <pre><code>from sagemaker.experiments import Run\n\nwith Run(experiment_name=\"my-experiment\", run_name=\"run-1\") as run:\n    run.log_parameter(\"learning_rate\", 0.01)\n    run.log_metric(\"accuracy\", 0.95)\n    run.log_artifact(name=\"model\", value=\"s3://bucket/model.tar.gz\")\n</code></pre>"},{"location":"domain-2-model-development/model-versioning/#best-practices","title":"Best Practices","text":"<p>!!! tip \"Versioning Best Practices\" 1. Use Model Registry for all production models 2. Implement approval workflows for governance 3. Track metrics with each model version 4. Use lineage for reproducibility 5. Tag models with relevant metadata</p>"},{"location":"domain-2-model-development/model-versioning/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Model Registry for versioning and governance - Approval status gates deployment - Lineage tracks data\u2192training\u2192model\u2192deployment - Experiments for comparing model runs</p>"},{"location":"domain-2-model-development/sagemaker-training/","title":"SageMaker Training","text":""},{"location":"domain-2-model-development/sagemaker-training/#overview","title":"Overview","text":"<p>Amazon SageMaker provides managed infrastructure for training ML models.</p>"},{"location":"domain-2-model-development/sagemaker-training/#training-job-components","title":"Training Job Components","text":"<pre><code>from sagemaker.estimator import Estimator\n\nestimator = Estimator(\n    image_uri=training_image,\n    role=role,\n    instance_count=1,\n    instance_type=\"ml.m5.xlarge\",\n    output_path=\"s3://bucket/output/\",\n    hyperparameters={\n        \"epochs\": 10,\n        \"learning_rate\": 0.01\n    }\n)\n\nestimator.fit({\n    \"train\": \"s3://bucket/train/\",\n    \"validation\": \"s3://bucket/validation/\"\n})\n</code></pre>"},{"location":"domain-2-model-development/sagemaker-training/#instance-types","title":"Instance Types","text":"Category Instance Types Use Case General Purpose ml.m5.* Balanced compute Compute Optimized ml.c5.* CPU-intensive GPU ml.p3., ml.g4dn. Deep learning Memory Optimized ml.r5.* Large datasets"},{"location":"domain-2-model-development/sagemaker-training/#training-modes","title":"Training Modes","text":""},{"location":"domain-2-model-development/sagemaker-training/#file-mode","title":"File Mode","text":"<ul> <li>Data downloaded to instance</li> <li>Best for iterative access</li> <li>Default mode</li> </ul>"},{"location":"domain-2-model-development/sagemaker-training/#pipe-mode","title":"Pipe Mode","text":"<ul> <li>Data streamed from S3</li> <li>No download wait time</li> <li>Best for large datasets</li> </ul>"},{"location":"domain-2-model-development/sagemaker-training/#fastfile-mode","title":"FastFile Mode","text":"<ul> <li>POSIX-compliant access</li> <li>Lazy loading</li> <li>Best for random access patterns</li> </ul>"},{"location":"domain-2-model-development/sagemaker-training/#distributed-training","title":"Distributed Training","text":""},{"location":"domain-2-model-development/sagemaker-training/#data-parallelism","title":"Data Parallelism","text":"<p>Split data across instances, each has full model copy.</p> <pre><code>from sagemaker.pytorch import PyTorch\n\nestimator = PyTorch(\n    entry_point=\"train.py\",\n    instance_count=4,\n    instance_type=\"ml.p3.16xlarge\",\n    distribution={\"smdistributed\": {\"dataparallel\": {\"enabled\": True}}}\n)\n</code></pre>"},{"location":"domain-2-model-development/sagemaker-training/#model-parallelism","title":"Model Parallelism","text":"<p>Split model across instances for large models.</p> <pre><code>distribution={\n    \"smdistributed\": {\n        \"modelparallel\": {\n            \"enabled\": True,\n            \"parameters\": {\"partitions\": 2}\n        }\n    }\n}\n</code></pre>"},{"location":"domain-2-model-development/sagemaker-training/#spot-training","title":"Spot Training","text":"<p>Save up to 90% on training costs.</p> <pre><code>estimator = Estimator(\n    ...\n    use_spot_instances=True,\n    max_wait=3600,  # Maximum wait time\n    max_run=1800,   # Maximum run time\n    checkpoint_s3_uri=\"s3://bucket/checkpoints/\"\n)\n</code></pre>"},{"location":"domain-2-model-development/sagemaker-training/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Use Pipe Mode for large datasets - Use Spot Instances with checkpointing for cost savings - Data Parallelism for scaling with batch size - Model Parallelism for models that don't fit in memory</p>"},{"location":"domain-3-deployment-orchestration/","title":"Domain 3: Deployment and Orchestration of ML Workflows","text":"<p>Weight: 22% of scored content</p> <p>This domain covers deploying models and automating ML pipelines.</p>"},{"location":"domain-3-deployment-orchestration/#topics-covered","title":"Topics Covered","text":"Topic Description SageMaker Endpoints Real-time, Serverless, Async Batch Transform Batch inference SageMaker Pipelines MLOps workflows Step Functions Workflow orchestration Container Deployment ECR, ECS, EKS Auto Scaling Scaling endpoints"},{"location":"domain-3-deployment-orchestration/#key-concepts","title":"Key Concepts","text":""},{"location":"domain-3-deployment-orchestration/#deployment-options","title":"Deployment Options","text":"<pre><code>graph TD\n    A[Model Artifact] --&gt; B{Deployment Type}\n    B --&gt; C[Real-time Endpoint]\n    B --&gt; D[Serverless Endpoint]\n    B --&gt; E[Async Endpoint]\n    B --&gt; F[Batch Transform]\n    C --&gt; G[Low Latency]\n    D --&gt; H[Cost Optimization]\n    E --&gt; I[Large Payloads]\n    F --&gt; J[Batch Processing]</code></pre>"},{"location":"domain-3-deployment-orchestration/#choosing-endpoint-type","title":"Choosing Endpoint Type","text":"Type Latency Cost Use Case Real-time Milliseconds Pay per hour Interactive apps Serverless Seconds (cold start) Pay per request Variable traffic Async Minutes Pay per hour Large payloads Batch Hours Pay per job Offline processing"},{"location":"domain-3-deployment-orchestration/#study-checklist","title":"Study Checklist","text":"<ul> <li> Understand endpoint types and when to use each</li> <li> Know SageMaker Pipelines components</li> <li> Understand Step Functions for orchestration</li> <li> Know container requirements for deployment</li> <li> Understand auto-scaling configuration</li> </ul>"},{"location":"domain-3-deployment-orchestration/auto-scaling/","title":"Auto Scaling","text":""},{"location":"domain-3-deployment-orchestration/auto-scaling/#overview","title":"Overview","text":"<p>Automatically adjust endpoint capacity based on demand.</p>"},{"location":"domain-3-deployment-orchestration/auto-scaling/#application-auto-scaling","title":"Application Auto Scaling","text":"<p>SageMaker uses Application Auto Scaling for endpoints.</p>"},{"location":"domain-3-deployment-orchestration/auto-scaling/#target-tracking-scaling","title":"Target Tracking Scaling","text":"<p>Scale based on a target metric.</p> <pre><code>import boto3\n\nasg_client = boto3.client(\"application-autoscaling\")\n\n# Register scalable target\nasg_client.register_scalable_target(\n    ServiceNamespace=\"sagemaker\",\n    ResourceId=\"endpoint/my-endpoint/variant/AllTraffic\",\n    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n    MinCapacity=1,\n    MaxCapacity=10\n)\n\n# Create scaling policy\nasg_client.put_scaling_policy(\n    PolicyName=\"target-tracking-policy\",\n    ServiceNamespace=\"sagemaker\",\n    ResourceId=\"endpoint/my-endpoint/variant/AllTraffic\",\n    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n    PolicyType=\"TargetTrackingScaling\",\n    TargetTrackingScalingPolicyConfiguration={\n        \"TargetValue\": 70.0,\n        \"PredefinedMetricSpecification\": {\n            \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\"\n        },\n        \"ScaleInCooldown\": 300,\n        \"ScaleOutCooldown\": 60\n    }\n)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/auto-scaling/#step-scaling","title":"Step Scaling","text":"<p>Scale in steps based on alarm thresholds.</p> <pre><code>asg_client.put_scaling_policy(\n    PolicyName=\"step-scaling-policy\",\n    ServiceNamespace=\"sagemaker\",\n    ResourceId=\"endpoint/my-endpoint/variant/AllTraffic\",\n    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n    PolicyType=\"StepScaling\",\n    StepScalingPolicyConfiguration={\n        \"AdjustmentType\": \"ChangeInCapacity\",\n        \"StepAdjustments\": [\n            {\"MetricIntervalLowerBound\": 0, \"MetricIntervalUpperBound\": 50, \"ScalingAdjustment\": 1},\n            {\"MetricIntervalLowerBound\": 50, \"ScalingAdjustment\": 2}\n        ],\n        \"Cooldown\": 60\n    }\n)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/auto-scaling/#scaling-metrics","title":"Scaling Metrics","text":"Metric Description InvocationsPerInstance Average invocations per instance CPUUtilization CPU usage percentage MemoryUtilization Memory usage percentage GPUUtilization GPU usage percentage DiskUtilization Disk usage percentage"},{"location":"domain-3-deployment-orchestration/auto-scaling/#cooldown-periods","title":"Cooldown Periods","text":"Type Description Typical Value Scale Out Wait after adding capacity 60 seconds Scale In Wait after removing capacity 300 seconds"},{"location":"domain-3-deployment-orchestration/auto-scaling/#scheduled-scaling","title":"Scheduled Scaling","text":"<p>Scale based on known patterns.</p> <pre><code>asg_client.put_scheduled_action(\n    ServiceNamespace=\"sagemaker\",\n    ScheduledActionName=\"scale-up-morning\",\n    ResourceId=\"endpoint/my-endpoint/variant/AllTraffic\",\n    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n    Schedule=\"cron(0 8 * * ? *)\",  # 8 AM daily\n    ScalableTargetAction={\n        \"MinCapacity\": 5,\n        \"MaxCapacity\": 20\n    }\n)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/auto-scaling/#best-practices","title":"Best Practices","text":"<p>!!! tip \"Scaling Optimization\" 1. Use target tracking for simplicity 2. Set appropriate cooldown periods 3. Monitor CloudWatch metrics 4. Test scaling behavior before production 5. Consider scheduled scaling for predictable traffic</p>"},{"location":"domain-3-deployment-orchestration/auto-scaling/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Target tracking is simplest approach - InvocationsPerInstance common metric - Scale out cooldown &lt; Scale in cooldown - Scheduled scaling for predictable patterns</p>"},{"location":"domain-3-deployment-orchestration/batch-transform/","title":"Batch Transform","text":""},{"location":"domain-3-deployment-orchestration/batch-transform/#overview","title":"Overview","text":"<p>Run inference on large datasets without deploying an endpoint.</p>"},{"location":"domain-3-deployment-orchestration/batch-transform/#when-to-use","title":"When to Use","text":"<ul> <li>Large dataset inference</li> <li>No real-time requirements</li> <li>Periodic batch predictions</li> <li>Cost optimization (no always-on endpoint)</li> </ul>"},{"location":"domain-3-deployment-orchestration/batch-transform/#creating-a-batch-transform-job","title":"Creating a Batch Transform Job","text":"<pre><code>from sagemaker.transformer import Transformer\n\ntransformer = Transformer(\n    model_name=\"my-model\",\n    instance_count=2,\n    instance_type=\"ml.m5.xlarge\",\n    output_path=\"s3://bucket/batch-output/\",\n    strategy=\"SingleRecord\",  # or \"MultiRecord\"\n    assemble_with=\"Line\",\n    max_payload=6  # MB\n)\n\ntransformer.transform(\n    data=\"s3://bucket/batch-input/\",\n    content_type=\"text/csv\",\n    split_type=\"Line\"\n)\n\ntransformer.wait()\n</code></pre>"},{"location":"domain-3-deployment-orchestration/batch-transform/#configuration-options","title":"Configuration Options","text":"Parameter Options Description strategy SingleRecord, MultiRecord How to batch records split_type Line, RecordIO, None How to split input assemble_with Line, None How to assemble output max_payload 0-100 MB Max payload per request max_concurrent_transforms 1-100 Parallel processing"},{"location":"domain-3-deployment-orchestration/batch-transform/#data-formats","title":"Data Formats","text":""},{"location":"domain-3-deployment-orchestration/batch-transform/#input","title":"Input","text":"<pre><code>s3://bucket/input/\n\u251c\u2500\u2500 file1.csv\n\u251c\u2500\u2500 file2.csv\n\u2514\u2500\u2500 file3.csv\n</code></pre>"},{"location":"domain-3-deployment-orchestration/batch-transform/#output","title":"Output","text":"<pre><code>s3://bucket/output/\n\u251c\u2500\u2500 file1.csv.out\n\u251c\u2500\u2500 file2.csv.out\n\u2514\u2500\u2500 file3.csv.out\n</code></pre>"},{"location":"domain-3-deployment-orchestration/batch-transform/#batch-transform-vs-endpoint","title":"Batch Transform vs Endpoint","text":"Aspect Batch Transform Real-time Endpoint Use Case Large batch processing Real-time predictions Latency Minutes to hours Milliseconds Cost Pay per job Pay per hour Scaling Automatic Manual/Auto Infrastructure Transient Persistent"},{"location":"domain-3-deployment-orchestration/batch-transform/#best-practices","title":"Best Practices","text":"<p>!!! tip \"Optimization\" 1. Use MultiRecord strategy for throughput 2. Increase max_concurrent_transforms for parallelism 3. Use appropriate instance types for your workload 4. Partition input data for faster processing</p>"},{"location":"domain-3-deployment-orchestration/batch-transform/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Batch Transform for offline, large-scale inference - No endpoint maintenance required - Cost-effective for infrequent predictions - Supports data distribution across instances</p>"},{"location":"domain-3-deployment-orchestration/container-deployment/","title":"Container Deployment","text":""},{"location":"domain-3-deployment-orchestration/container-deployment/#overview","title":"Overview","text":"<p>Deploying ML models using containers on AWS.</p>"},{"location":"domain-3-deployment-orchestration/container-deployment/#amazon-ecr","title":"Amazon ECR","text":"<p>Container registry for storing Docker images.</p> <pre><code># Build and push image\naws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin account.dkr.ecr.us-east-1.amazonaws.com\n\ndocker build -t my-inference-image .\ndocker tag my-inference-image:latest account.dkr.ecr.us-east-1.amazonaws.com/my-repo:latest\ndocker push account.dkr.ecr.us-east-1.amazonaws.com/my-repo:latest\n</code></pre>"},{"location":"domain-3-deployment-orchestration/container-deployment/#sagemaker-container-requirements","title":"SageMaker Container Requirements","text":""},{"location":"domain-3-deployment-orchestration/container-deployment/#directory-structure","title":"Directory Structure","text":"<pre><code>/opt/ml/\n\u251c\u2500\u2500 model/           # Model artifacts\n\u251c\u2500\u2500 input/\n\u2502   \u251c\u2500\u2500 config/      # Hyperparameters, resource config\n\u2502   \u2514\u2500\u2500 data/        # Training data channels\n\u2514\u2500\u2500 output/          # Model output, failure info\n</code></pre>"},{"location":"domain-3-deployment-orchestration/container-deployment/#inference-container","title":"Inference Container","text":"<pre><code>FROM python:3.9-slim\n\nRUN pip install flask gunicorn scikit-learn\n\nCOPY inference.py /opt/program/\nCOPY serve /opt/program/\n\nENV PATH=\"/opt/program:${PATH}\"\n\nWORKDIR /opt/program\n\nENTRYPOINT [\"python\", \"serve\"]\n</code></pre>"},{"location":"domain-3-deployment-orchestration/container-deployment/#required-endpoints","title":"Required Endpoints","text":"Endpoint Method Purpose /ping GET Health check /invocations POST Inference requests <pre><code># serve.py\nfrom flask import Flask, request\nimport json\n\napp = Flask(__name__)\n\n@app.route(\"/ping\", methods=[\"GET\"])\ndef ping():\n    return \"\", 200\n\n@app.route(\"/invocations\", methods=[\"POST\"])\ndef invocations():\n    data = request.get_json()\n    prediction = model.predict(data)\n    return json.dumps({\"prediction\": prediction})\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=8080)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/container-deployment/#bring-your-own-container-byoc","title":"Bring Your Own Container (BYOC)","text":"<pre><code>from sagemaker.model import Model\n\nmodel = Model(\n    image_uri=\"account.dkr.ecr.region.amazonaws.com/my-repo:latest\",\n    model_data=\"s3://bucket/model.tar.gz\",\n    role=role\n)\n\nmodel.deploy(\n    instance_type=\"ml.m5.large\",\n    initial_instance_count=1\n)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/container-deployment/#ecseks-deployment","title":"ECS/EKS Deployment","text":"<p>For non-SageMaker deployments.</p>"},{"location":"domain-3-deployment-orchestration/container-deployment/#ecs","title":"ECS","text":"<pre><code># task-definition.json\n{\n  \"family\": \"ml-inference\",\n  \"containerDefinitions\":\n    [\n      {\n        \"name\": \"inference\",\n        \"image\": \"account.dkr.ecr.region.amazonaws.com/my-repo:latest\",\n        \"memory\": 2048,\n        \"cpu\": 1024,\n        \"portMappings\": [{ \"containerPort\": 8080 }],\n      },\n    ],\n}\n</code></pre>"},{"location":"domain-3-deployment-orchestration/container-deployment/#eks","title":"EKS","text":"<pre><code># deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ml-inference\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: ml-inference\n  template:\n    spec:\n      containers:\n        - name: inference\n          image: account.dkr.ecr.region.amazonaws.com/my-repo:latest\n          ports:\n            - containerPort: 8080\n</code></pre>"},{"location":"domain-3-deployment-orchestration/container-deployment/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - ECR for storing container images - SageMaker containers need /ping and /invocations - BYOC for custom frameworks - ECS/EKS for non-SageMaker deployments</p>"},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/","title":"SageMaker Endpoints","text":""},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/#overview","title":"Overview","text":"<p>Deploy models for real-time inference.</p>"},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/#endpoint-types","title":"Endpoint Types","text":""},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/#real-time-inference","title":"Real-time Inference","text":"<p>Always-on endpoints for low-latency predictions.</p> <pre><code>from sagemaker.model import Model\n\nmodel = Model(\n    image_uri=inference_image,\n    model_data=\"s3://bucket/model.tar.gz\",\n    role=role\n)\n\npredictor = model.deploy(\n    initial_instance_count=2,\n    instance_type=\"ml.m5.large\",\n    endpoint_name=\"my-endpoint\"\n)\n\n# Invoke\nresponse = predictor.predict(data)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/#serverless-inference","title":"Serverless Inference","text":"<p>Pay-per-request with automatic scaling.</p> <pre><code>from sagemaker.serverless import ServerlessInferenceConfig\n\nserverless_config = ServerlessInferenceConfig(\n    memory_size_in_mb=2048,\n    max_concurrency=10\n)\n\npredictor = model.deploy(\n    serverless_inference_config=serverless_config,\n    endpoint_name=\"serverless-endpoint\"\n)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/#asynchronous-inference","title":"Asynchronous Inference","text":"<p>For large payloads and long processing times.</p> <pre><code>from sagemaker.async_inference import AsyncInferenceConfig\n\nasync_config = AsyncInferenceConfig(\n    output_path=\"s3://bucket/async-output/\",\n    max_concurrent_invocations_per_instance=4,\n    notification_config={\n        \"SuccessTopic\": success_topic_arn,\n        \"ErrorTopic\": error_topic_arn\n    }\n)\n\npredictor = model.deploy(\n    instance_type=\"ml.m5.large\",\n    initial_instance_count=1,\n    async_inference_config=async_config\n)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/#multi-model-endpoints","title":"Multi-Model Endpoints","text":"<p>Host multiple models on single endpoint.</p> <pre><code>from sagemaker.multidatamodel import MultiDataModel\n\nmme = MultiDataModel(\n    name=\"multi-model-endpoint\",\n    model_data_prefix=\"s3://bucket/models/\",\n    image_uri=inference_image,\n    role=role\n)\n\npredictor = mme.deploy(\n    initial_instance_count=1,\n    instance_type=\"ml.m5.large\"\n)\n\n# Invoke specific model\npredictor.predict(data, target_model=\"model-a.tar.gz\")\n</code></pre>"},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/#inference-components","title":"Inference Components","text":"<p>Share resources across models.</p> <ul> <li>Copy-based scaling</li> <li>Fine-grained resource allocation</li> <li>Cost optimization for multiple models</li> </ul>"},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/#endpoint-comparison","title":"Endpoint Comparison","text":"Feature Real-time Serverless Async Cold Start No Yes No Max Payload 6 MB 6 MB 1 GB Max Timeout 60s 60s 15 min Scaling Manual/Auto Automatic Manual/Auto Billing Per hour Per request Per hour"},{"location":"domain-3-deployment-orchestration/sagemaker-endpoints/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Endpoint Selection\" - Real-time: Consistent traffic, low latency required - Serverless: Variable traffic, cost sensitive - Async: Large payloads, long processing - Multi-model: Many similar models, cost optimization</p>"},{"location":"domain-3-deployment-orchestration/sagemaker-pipelines/","title":"SageMaker Pipelines","text":""},{"location":"domain-3-deployment-orchestration/sagemaker-pipelines/#overview","title":"Overview","text":"<p>Native MLOps service for building, automating, and managing ML workflows.</p>"},{"location":"domain-3-deployment-orchestration/sagemaker-pipelines/#pipeline-components","title":"Pipeline Components","text":"<pre><code>graph LR\n    A[Data Processing] --&gt; B[Training]\n    B --&gt; C[Evaluation]\n    C --&gt; D{Condition}\n    D --&gt;|Pass| E[Register Model]\n    D --&gt;|Fail| F[Stop]\n    E --&gt; G[Deploy]</code></pre>"},{"location":"domain-3-deployment-orchestration/sagemaker-pipelines/#step-types","title":"Step Types","text":"Step Description ProcessingStep Data processing with SageMaker Processing TrainingStep Model training TuningStep Hyperparameter tuning TransformStep Batch inference CreateModelStep Create model from artifacts RegisterModel Register to Model Registry ConditionStep Conditional branching FailStep Fail the pipeline LambdaStep Run Lambda function CallbackStep Wait for external process"},{"location":"domain-3-deployment-orchestration/sagemaker-pipelines/#creating-a-pipeline","title":"Creating a Pipeline","text":"<pre><code>from sagemaker.workflow.pipeline import Pipeline\nfrom sagemaker.workflow.steps import ProcessingStep, TrainingStep\nfrom sagemaker.workflow.parameters import ParameterString\n\n# Define parameters\ninput_data = ParameterString(name=\"InputData\", default_value=\"s3://bucket/data/\")\n\n# Processing step\nprocessing_step = ProcessingStep(\n    name=\"PreprocessData\",\n    processor=processor,\n    inputs=[ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\")],\n    outputs=[ProcessingOutput(source=\"/opt/ml/processing/output\", destination=\"s3://bucket/processed/\")]\n)\n\n# Training step\ntraining_step = TrainingStep(\n    name=\"TrainModel\",\n    estimator=estimator,\n    inputs={\"train\": processing_step.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri}\n)\n\n# Create pipeline\npipeline = Pipeline(\n    name=\"my-ml-pipeline\",\n    parameters=[input_data],\n    steps=[processing_step, training_step]\n)\n\npipeline.upsert(role_arn=role)\npipeline.start()\n</code></pre>"},{"location":"domain-3-deployment-orchestration/sagemaker-pipelines/#conditional-steps","title":"Conditional Steps","text":"<pre><code>from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\nfrom sagemaker.workflow.condition_step import ConditionStep\n\ncondition = ConditionGreaterThanOrEqualTo(\n    left=evaluation_step.properties.ProcessingOutputConfig.Outputs[\"metrics\"].S3Output.S3Uri,\n    right=0.8\n)\n\ncondition_step = ConditionStep(\n    name=\"CheckAccuracy\",\n    conditions=[condition],\n    if_steps=[register_step, deploy_step],\n    else_steps=[fail_step]\n)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/sagemaker-pipelines/#pipeline-parameters","title":"Pipeline Parameters","text":"<pre><code>from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat\n\ninstance_count = ParameterInteger(name=\"InstanceCount\", default_value=1)\nlearning_rate = ParameterFloat(name=\"LearningRate\", default_value=0.01)\n\n# Use in estimator\nestimator = Estimator(\n    instance_count=instance_count,\n    hyperparameters={\"learning_rate\": learning_rate}\n)\n</code></pre>"},{"location":"domain-3-deployment-orchestration/sagemaker-pipelines/#best-practices","title":"Best Practices","text":"<p>!!! tip \"Pipeline Design\" 1. Use parameters for flexibility 2. Add condition steps for quality gates 3. Register models only after validation 4. Use caching for faster re-runs 5. Version your pipeline definitions</p>"},{"location":"domain-3-deployment-orchestration/sagemaker-pipelines/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Pipelines automate end-to-end ML workflows - ConditionStep for quality gates before deployment - Parameters make pipelines reusable - Integration with Model Registry for governance</p>"},{"location":"domain-3-deployment-orchestration/step-functions/","title":"Step Functions","text":""},{"location":"domain-3-deployment-orchestration/step-functions/#overview","title":"Overview","text":"<p>Serverless workflow orchestration for ML and data pipelines.</p>"},{"location":"domain-3-deployment-orchestration/step-functions/#key-features","title":"Key Features","text":"<ul> <li>Visual workflow designer</li> <li>Native AWS service integrations</li> <li>Error handling and retries</li> <li>Parallel execution</li> <li>Human approval steps</li> </ul>"},{"location":"domain-3-deployment-orchestration/step-functions/#state-types","title":"State Types","text":"State Description Task Execute work (Lambda, SageMaker, etc.) Choice Conditional branching Parallel Concurrent execution Map Iterate over items Wait Pause execution Pass Pass input to output Succeed/Fail Terminal states"},{"location":"domain-3-deployment-orchestration/step-functions/#sagemaker-integration","title":"SageMaker Integration","text":"<pre><code>{\n  \"Comment\": \"ML Training Pipeline\",\n  \"StartAt\": \"CreateTrainingJob\",\n  \"States\": {\n    \"CreateTrainingJob\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\",\n      \"Parameters\": {\n        \"TrainingJobName.$\": \"$$.Execution.Name\",\n        \"AlgorithmSpecification\": {\n          \"TrainingImage\": \"image-uri\",\n          \"TrainingInputMode\": \"File\"\n        },\n        \"RoleArn\": \"arn:aws:iam::account:role/SageMakerRole\",\n        \"InputDataConfig\": [\n          {\n            \"ChannelName\": \"train\",\n            \"DataSource\": {\n              \"S3DataSource\": {\n                \"S3Uri\": \"s3://bucket/train/\"\n              }\n            }\n          }\n        ],\n        \"OutputDataConfig\": {\n          \"S3OutputPath\": \"s3://bucket/output/\"\n        },\n        \"ResourceConfig\": {\n          \"InstanceCount\": 1,\n          \"InstanceType\": \"ml.m5.large\",\n          \"VolumeSizeInGB\": 50\n        }\n      },\n      \"Next\": \"CreateModel\"\n    },\n    \"CreateModel\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:states:::sagemaker:createModel\",\n      \"Parameters\": {\n        \"ModelName.$\": \"$$.Execution.Name\",\n        \"PrimaryContainer\": {\n          \"Image\": \"inference-image\",\n          \"ModelDataUrl.$\": \"$.ModelArtifacts.S3ModelArtifacts\"\n        },\n        \"ExecutionRoleArn\": \"role-arn\"\n      },\n      \"End\": true\n    }\n  }\n}\n</code></pre>"},{"location":"domain-3-deployment-orchestration/step-functions/#error-handling","title":"Error Handling","text":"<pre><code>{\n  \"Type\": \"Task\",\n  \"Resource\": \"...\",\n  \"Retry\": [\n    {\n      \"ErrorEquals\": [\"States.TaskFailed\"],\n      \"IntervalSeconds\": 30,\n      \"MaxAttempts\": 3,\n      \"BackoffRate\": 2.0\n    }\n  ],\n  \"Catch\": [\n    {\n      \"ErrorEquals\": [\"States.ALL\"],\n      \"ResultPath\": \"$.error\",\n      \"Next\": \"HandleError\"\n    }\n  ]\n}\n</code></pre>"},{"location":"domain-3-deployment-orchestration/step-functions/#step-functions-vs-sagemaker-pipelines","title":"Step Functions vs SageMaker Pipelines","text":"Feature Step Functions SageMaker Pipelines Focus General orchestration ML-specific Integrations 200+ AWS services SageMaker-centric Caching No Yes ML Features Basic Rich (lineage, registry) Visual Editor Yes Limited"},{"location":"domain-3-deployment-orchestration/step-functions/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"When to Use\" - Step Functions: Complex workflows, multi-service orchestration - SageMaker Pipelines: ML-specific, need caching/lineage - Combine both for comprehensive MLOps</p>"},{"location":"domain-4-monitoring-security/","title":"Domain 4: ML Solution Monitoring, Maintenance, and Security","text":"<p>Weight: 24% of scored content</p> <p>This domain covers monitoring, cost optimization, and security for ML solutions.</p>"},{"location":"domain-4-monitoring-security/#topics-covered","title":"Topics Covered","text":"Topic Description Model Monitoring Model Monitor, data drift CloudWatch Logging CloudWatch, CloudTrail Cost Optimization Cost Explorer, Budgets IAM Security IAM, KMS, Secrets Manager Compliance Macie, Config"},{"location":"domain-4-monitoring-security/#key-concepts","title":"Key Concepts","text":""},{"location":"domain-4-monitoring-security/#monitoring-workflow","title":"Monitoring Workflow","text":"<pre><code>graph LR\n    A[Production Data] --&gt; B[Model Monitor]\n    B --&gt; C{Drift Detected?}\n    C --&gt;|Yes| D[CloudWatch Alarm]\n    D --&gt; E[SNS Notification]\n    E --&gt; F[Retrain Model]\n    C --&gt;|No| G[Continue Monitoring]</code></pre>"},{"location":"domain-4-monitoring-security/#security-layers","title":"Security Layers","text":"Layer Services Identity IAM, IAM Identity Center Encryption KMS, S3 encryption Network VPC, Security Groups Data Macie, data masking Secrets Secrets Manager"},{"location":"domain-4-monitoring-security/#study-checklist","title":"Study Checklist","text":"<ul> <li> Understand SageMaker Model Monitor types</li> <li> Know CloudWatch metrics and alarms</li> <li> Understand cost optimization strategies</li> <li> Know IAM best practices for ML</li> <li> Understand encryption options (KMS)</li> <li> Know VPC configuration for SageMaker</li> </ul>"},{"location":"domain-4-monitoring-security/cloudwatch-logging/","title":"CloudWatch Logging","text":""},{"location":"domain-4-monitoring-security/cloudwatch-logging/#overview","title":"Overview","text":"<p>Monitor ML infrastructure with CloudWatch and CloudTrail.</p>"},{"location":"domain-4-monitoring-security/cloudwatch-logging/#amazon-cloudwatch","title":"Amazon CloudWatch","text":""},{"location":"domain-4-monitoring-security/cloudwatch-logging/#key-metrics-for-sagemaker","title":"Key Metrics for SageMaker","text":"Metric Description Invocations Number of requests InvocationsPerInstance Requests per instance ModelLatency Inference time OverheadLatency SageMaker overhead Invocation4XXErrors Client errors Invocation5XXErrors Server errors CPUUtilization CPU usage MemoryUtilization Memory usage GPUUtilization GPU usage DiskUtilization Disk usage"},{"location":"domain-4-monitoring-security/cloudwatch-logging/#creating-dashboards","title":"Creating Dashboards","text":"<pre><code>import boto3\n\ncloudwatch = boto3.client(\"cloudwatch\")\n\ncloudwatch.put_dashboard(\n    DashboardName=\"ML-Monitoring\",\n    DashboardBody=json.dumps({\n        \"widgets\": [\n            {\n                \"type\": \"metric\",\n                \"properties\": {\n                    \"title\": \"Invocations\",\n                    \"metrics\": [\n                        [\"AWS/SageMaker\", \"Invocations\", \"EndpointName\", \"my-endpoint\"]\n                    ],\n                    \"period\": 60\n                }\n            },\n            {\n                \"type\": \"metric\",\n                \"properties\": {\n                    \"title\": \"Latency\",\n                    \"metrics\": [\n                        [\"AWS/SageMaker\", \"ModelLatency\", \"EndpointName\", \"my-endpoint\"]\n                    ],\n                    \"period\": 60\n                }\n            }\n        ]\n    })\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/cloudwatch-logging/#creating-alarms","title":"Creating Alarms","text":"<pre><code>cloudwatch.put_metric_alarm(\n    AlarmName=\"HighLatency\",\n    MetricName=\"ModelLatency\",\n    Namespace=\"AWS/SageMaker\",\n    Dimensions=[{\"Name\": \"EndpointName\", \"Value\": \"my-endpoint\"}],\n    Statistic=\"Average\",\n    Period=300,\n    EvaluationPeriods=2,\n    Threshold=1000000,  # microseconds\n    ComparisonOperator=\"GreaterThanThreshold\",\n    AlarmActions=[sns_topic_arn]\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/cloudwatch-logging/#cloudwatch-logs","title":"CloudWatch Logs","text":""},{"location":"domain-4-monitoring-security/cloudwatch-logging/#sagemaker-log-groups","title":"SageMaker Log Groups","text":"Log Group Contents /aws/sagemaker/TrainingJobs Training output /aws/sagemaker/Endpoints Inference logs /aws/sagemaker/ProcessingJobs Processing output"},{"location":"domain-4-monitoring-security/cloudwatch-logging/#log-insights-queries","title":"Log Insights Queries","text":"<pre><code>-- Find errors in last hour\nfields @timestamp, @message\n| filter @message like /ERROR/\n| sort @timestamp desc\n| limit 100\n\n-- Latency percentiles\nstats percentile(@duration, 50) as p50,\n      percentile(@duration, 99) as p99\nby bin(1h)\n</code></pre>"},{"location":"domain-4-monitoring-security/cloudwatch-logging/#aws-cloudtrail","title":"AWS CloudTrail","text":"<p>Audit API calls for compliance.</p>"},{"location":"domain-4-monitoring-security/cloudwatch-logging/#key-events","title":"Key Events","text":"Event Description CreateEndpoint Endpoint creation DeleteEndpoint Endpoint deletion UpdateEndpoint Endpoint updates CreateTrainingJob Training job start InvokeEndpoint Inference calls"},{"location":"domain-4-monitoring-security/cloudwatch-logging/#example-query","title":"Example Query","text":"<pre><code>SELECT eventTime, eventName, userIdentity.userName, errorCode\nFROM cloudtrail_logs\nWHERE eventSource = 'sagemaker.amazonaws.com'\n  AND eventTime &gt; '2024-01-01'\nORDER BY eventTime DESC\n</code></pre>"},{"location":"domain-4-monitoring-security/cloudwatch-logging/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - CloudWatch Metrics: Performance monitoring - CloudWatch Logs: Application logging - CloudWatch Alarms: Automated alerting - CloudTrail: API audit logging - Use Log Insights for querying logs</p>"},{"location":"domain-4-monitoring-security/compliance/","title":"Compliance","text":""},{"location":"domain-4-monitoring-security/compliance/#overview","title":"Overview","text":"<p>Ensuring ML solutions meet compliance and governance requirements.</p>"},{"location":"domain-4-monitoring-security/compliance/#amazon-macie","title":"Amazon Macie","text":"<p>Discover and protect sensitive data in S3.</p>"},{"location":"domain-4-monitoring-security/compliance/#key-features","title":"Key Features","text":"<ul> <li>Automatic sensitive data discovery</li> <li>PII detection</li> <li>Custom data identifiers</li> <li>Findings and alerts</li> </ul> <pre><code>import boto3\n\nmacie = boto3.client(\"macie2\")\n\n# Enable Macie\nmacie.enable_macie()\n\n# Create classification job\nmacie.create_classification_job(\n    name=\"ml-data-scan\",\n    s3JobDefinition={\n        \"bucketDefinitions\": [{\n            \"accountId\": \"123456789012\",\n            \"buckets\": [\"my-ml-bucket\"]\n        }]\n    },\n    jobType=\"ONE_TIME\"\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/compliance/#aws-config","title":"AWS Config","text":"<p>Track resource compliance.</p>"},{"location":"domain-4-monitoring-security/compliance/#sagemaker-config-rules","title":"SageMaker Config Rules","text":"Rule Description sagemaker-endpoint-configuration-kms-key-configured Endpoint uses KMS sagemaker-notebook-instance-inside-vpc Notebook in VPC sagemaker-notebook-no-direct-internet-access No direct internet"},{"location":"domain-4-monitoring-security/compliance/#custom-config-rule","title":"Custom Config Rule","text":"<pre><code># Lambda function for custom rule\ndef evaluate_compliance(configuration_item):\n    if configuration_item[\"resourceType\"] != \"AWS::SageMaker::Endpoint\":\n        return \"NOT_APPLICABLE\"\n\n    # Check endpoint configuration\n    config = configuration_item[\"configuration\"]\n    if config.get(\"kmsKeyId\"):\n        return \"COMPLIANT\"\n    return \"NON_COMPLIANT\"\n</code></pre>"},{"location":"domain-4-monitoring-security/compliance/#data-governance","title":"Data Governance","text":""},{"location":"domain-4-monitoring-security/compliance/#aws-lake-formation","title":"AWS Lake Formation","text":"<p>Fine-grained access control for data lakes.</p> <ul> <li>Row-level security</li> <li>Column-level security</li> <li>Data sharing across accounts</li> </ul>"},{"location":"domain-4-monitoring-security/compliance/#sagemaker-governance","title":"SageMaker Governance","text":"Feature Purpose Model Cards Document model details Model Registry Version and approve models Lineage Tracking Track data to model"},{"location":"domain-4-monitoring-security/compliance/#model-cards","title":"Model Cards","text":"<p>Document model information for governance.</p> <pre><code>from sagemaker.model_card import ModelCard, ModelOverview\n\nmodel_card = ModelCard(\n    name=\"customer-churn-model\",\n    status=\"Draft\",\n    model_overview=ModelOverview(\n        model_description=\"Predicts customer churn probability\",\n        model_creator=\"Data Science Team\",\n        problem_type=\"Binary Classification\"\n    ),\n    intended_uses=IntendedUses(\n        purpose_of_model=\"Identify at-risk customers\",\n        intended_uses=\"Customer retention campaigns\",\n        factors_affecting_model_efficiency=\"Data recency\",\n        risk_rating=\"Medium\"\n    )\n)\n\nmodel_card.create()\n</code></pre>"},{"location":"domain-4-monitoring-security/compliance/#audit-logging","title":"Audit Logging","text":""},{"location":"domain-4-monitoring-security/compliance/#cloudtrail-for-compliance","title":"CloudTrail for Compliance","text":"<pre><code>-- Find all model deployments\nSELECT eventTime, userIdentity.userName, requestParameters.endpointName\nFROM cloudtrail_logs\nWHERE eventName = 'CreateEndpoint'\n  AND eventTime &gt; '2024-01-01'\nORDER BY eventTime DESC\n</code></pre>"},{"location":"domain-4-monitoring-security/compliance/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Macie for sensitive data discovery - Config rules for compliance checking - Lake Formation for data governance - Model Cards for model documentation - CloudTrail for audit logging</p>"},{"location":"domain-4-monitoring-security/cost-optimization/","title":"Cost Optimization","text":""},{"location":"domain-4-monitoring-security/cost-optimization/#overview","title":"Overview","text":"<p>Strategies for optimizing ML costs on AWS.</p>"},{"location":"domain-4-monitoring-security/cost-optimization/#aws-cost-management-tools","title":"AWS Cost Management Tools","text":"Tool Purpose Cost Explorer Visualize and analyze costs AWS Budgets Set cost alerts Savings Plans Commit to usage for discounts Spot Instances Use spare capacity Compute Optimizer Right-sizing recommendations"},{"location":"domain-4-monitoring-security/cost-optimization/#sagemaker-cost-optimization","title":"SageMaker Cost Optimization","text":""},{"location":"domain-4-monitoring-security/cost-optimization/#training-costs","title":"Training Costs","text":"<p>Spot Training</p> <p>Save up to 90% on training costs.</p> <pre><code>estimator = Estimator(\n    ...\n    use_spot_instances=True,\n    max_wait=3600,\n    max_run=1800,\n    checkpoint_s3_uri=\"s3://bucket/checkpoints/\"\n)\n</code></pre> <p>Right-sizing Instances</p> Instance Type Use Case ml.m5.* General purpose ml.c5.* CPU-intensive ml.p3./ml.g4dn. Deep learning ml.r5.* Memory-intensive <p>Managed Warm Pools</p> <p>Reduce training startup time.</p> <pre><code>estimator = Estimator(\n    ...\n    keep_alive_period_in_seconds=3600  # 1 hour\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/cost-optimization/#inference-costs","title":"Inference Costs","text":"<p>Serverless Endpoints</p> <p>Pay per request, no idle costs.</p> <pre><code>serverless_config = ServerlessInferenceConfig(\n    memory_size_in_mb=2048,\n    max_concurrency=10\n)\n</code></pre> <p>Multi-Model Endpoints</p> <p>Host multiple models on single instance.</p> <pre><code>mme = MultiDataModel(\n    name=\"mme-endpoint\",\n    model_data_prefix=\"s3://bucket/models/\",\n    image_uri=image_uri,\n    role=role\n)\n</code></pre> <p>Auto Scaling</p> <p>Scale to zero during low traffic (Serverless) or minimum capacity.</p>"},{"location":"domain-4-monitoring-security/cost-optimization/#storage-costs","title":"Storage Costs","text":"<ul> <li>Use S3 lifecycle policies for old data</li> <li>Clean up unused model artifacts</li> <li>Use appropriate storage classes</li> </ul>"},{"location":"domain-4-monitoring-security/cost-optimization/#aws-budgets","title":"AWS Budgets","text":"<pre><code>import boto3\n\nbudgets = boto3.client(\"budgets\")\n\nbudgets.create_budget(\n    AccountId=\"123456789012\",\n    Budget={\n        \"BudgetName\": \"ML-Monthly-Budget\",\n        \"BudgetLimit\": {\"Amount\": \"1000\", \"Unit\": \"USD\"},\n        \"TimeUnit\": \"MONTHLY\",\n        \"BudgetType\": \"COST\"\n    },\n    NotificationsWithSubscribers=[{\n        \"Notification\": {\n            \"NotificationType\": \"ACTUAL\",\n            \"ComparisonOperator\": \"GREATER_THAN\",\n            \"Threshold\": 80,\n            \"ThresholdType\": \"PERCENTAGE\"\n        },\n        \"Subscribers\": [{\n            \"SubscriptionType\": \"EMAIL\",\n            \"Address\": \"team@example.com\"\n        }]\n    }]\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/cost-optimization/#cost-allocation-tags","title":"Cost Allocation Tags","text":"<p>Track costs by project, team, or environment.</p> <pre><code>sagemaker.create_training_job(\n    ...\n    Tags=[\n        {\"Key\": \"Project\", \"Value\": \"CustomerChurn\"},\n        {\"Key\": \"Environment\", \"Value\": \"Production\"},\n        {\"Key\": \"Team\", \"Value\": \"DataScience\"}\n    ]\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/cost-optimization/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Strategies\" - Spot Instances for training (up to 90% savings) - Serverless endpoints for variable traffic - Multi-model endpoints for many models - Right-size instances with Compute Optimizer - Use Budgets for cost alerts</p>"},{"location":"domain-4-monitoring-security/iam-security/","title":"IAM Security","text":""},{"location":"domain-4-monitoring-security/iam-security/#overview","title":"Overview","text":"<p>Identity and access management for ML workloads.</p>"},{"location":"domain-4-monitoring-security/iam-security/#sagemaker-execution-roles","title":"SageMaker Execution Roles","text":"<p>Role that SageMaker assumes to access AWS resources.</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"sagemaker.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\n</code></pre>"},{"location":"domain-4-monitoring-security/iam-security/#common-permissions","title":"Common Permissions","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"s3:GetObject\", \"s3:PutObject\", \"s3:ListBucket\"],\n      \"Resource\": [\"arn:aws:s3:::my-bucket\", \"arn:aws:s3:::my-bucket/*\"]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:*:*:*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ecr:GetAuthorizationToken\",\n        \"ecr:BatchGetImage\",\n        \"ecr:GetDownloadUrlForLayer\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"domain-4-monitoring-security/iam-security/#aws-kms","title":"AWS KMS","text":"<p>Encryption at rest for ML data and models.</p>"},{"location":"domain-4-monitoring-security/iam-security/#creating-a-kms-key","title":"Creating a KMS Key","text":"<pre><code>import boto3\n\nkms = boto3.client(\"kms\")\n\nresponse = kms.create_key(\n    Description=\"Key for ML workloads\",\n    KeyUsage=\"ENCRYPT_DECRYPT\",\n    Tags=[{\"TagKey\": \"Project\", \"TagValue\": \"ML\"}]\n)\n\nkey_id = response[\"KeyMetadata\"][\"KeyId\"]\n</code></pre>"},{"location":"domain-4-monitoring-security/iam-security/#using-kms-with-sagemaker","title":"Using KMS with SageMaker","text":"<pre><code>from sagemaker.estimator import Estimator\n\nestimator = Estimator(\n    ...\n    output_kms_key=kms_key_arn,\n    volume_kms_key=kms_key_arn\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/iam-security/#aws-secrets-manager","title":"AWS Secrets Manager","text":"<p>Store sensitive credentials securely.</p> <pre><code>import boto3\nimport json\n\nsecrets_client = boto3.client(\"secretsmanager\")\n\n# Create secret\nsecrets_client.create_secret(\n    Name=\"ml/database-credentials\",\n    SecretString=json.dumps({\n        \"username\": \"admin\",\n        \"password\": \"secret123\"\n    })\n)\n\n# Retrieve secret\nresponse = secrets_client.get_secret_value(SecretId=\"ml/database-credentials\")\ncredentials = json.loads(response[\"SecretString\"])\n</code></pre>"},{"location":"domain-4-monitoring-security/iam-security/#vpc-configuration","title":"VPC Configuration","text":"<p>Isolate SageMaker resources in VPC.</p> <pre><code>from sagemaker import Estimator\n\nestimator = Estimator(\n    ...\n    subnets=[\"subnet-abc123\", \"subnet-def456\"],\n    security_group_ids=[\"sg-12345678\"]\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/iam-security/#vpc-endpoints","title":"VPC Endpoints","text":"Endpoint Purpose sagemaker.api SageMaker API calls sagemaker.runtime Inference calls s3 S3 access without internet"},{"location":"domain-4-monitoring-security/iam-security/#best-practices","title":"Best Practices","text":"<p>!!! tip \"Security Best Practices\" 1. Use least privilege IAM policies 2. Enable encryption at rest with KMS 3. Use VPC for network isolation 4. Store secrets in Secrets Manager 5. Enable CloudTrail for auditing 6. Use S3 bucket policies for data access control</p>"},{"location":"domain-4-monitoring-security/iam-security/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Execution role is assumed by SageMaker - KMS for encryption at rest - Secrets Manager for credentials - VPC for network isolation - VPC endpoints for private access</p>"},{"location":"domain-4-monitoring-security/model-monitoring/","title":"Model Monitoring","text":""},{"location":"domain-4-monitoring-security/model-monitoring/#overview","title":"Overview","text":"<p>SageMaker Model Monitor detects drift and quality issues in production models.</p>"},{"location":"domain-4-monitoring-security/model-monitoring/#monitor-types","title":"Monitor Types","text":"Type Description Data Quality Statistical drift in input data Model Quality Accuracy/performance degradation Bias Drift Changes in bias metrics Feature Attribution Changes in feature importance"},{"location":"domain-4-monitoring-security/model-monitoring/#data-quality-monitoring","title":"Data Quality Monitoring","text":"<p>Detect statistical drift in input features.</p> <pre><code>from sagemaker.model_monitor import DefaultModelMonitor\nfrom sagemaker.model_monitor.dataset_format import DatasetFormat\n\nmonitor = DefaultModelMonitor(\n    role=role,\n    instance_count=1,\n    instance_type=\"ml.m5.xlarge\",\n    volume_size_in_gb=20\n)\n\n# Create baseline from training data\nmonitor.suggest_baseline(\n    baseline_dataset=\"s3://bucket/training-data/\",\n    dataset_format=DatasetFormat.csv(header=True),\n    output_s3_uri=\"s3://bucket/baseline/\"\n)\n\n# Create monitoring schedule\nmonitor.create_monitoring_schedule(\n    monitor_schedule_name=\"my-monitoring-schedule\",\n    endpoint_input=endpoint_name,\n    output_s3_uri=\"s3://bucket/monitoring-output/\",\n    statistics=monitor.baseline_statistics(),\n    constraints=monitor.suggested_constraints(),\n    schedule_cron_expression=\"cron(0 * ? * * *)\"  # Hourly\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/model-monitoring/#model-quality-monitoring","title":"Model Quality Monitoring","text":"<p>Monitor prediction accuracy with ground truth.</p> <pre><code>from sagemaker.model_monitor import ModelQualityMonitor\n\nmodel_monitor = ModelQualityMonitor(\n    role=role,\n    instance_count=1,\n    instance_type=\"ml.m5.xlarge\"\n)\n\n# Create baseline\nmodel_monitor.suggest_baseline(\n    baseline_dataset=\"s3://bucket/predictions/\",\n    dataset_format=DatasetFormat.csv(),\n    output_s3_uri=\"s3://bucket/model-quality-baseline/\",\n    problem_type=\"BinaryClassification\",\n    inference_attribute=\"prediction\",\n    ground_truth_attribute=\"label\"\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/model-monitoring/#ground-truth-collection","title":"Ground Truth Collection","text":"<pre><code>from sagemaker.model_monitor import GroundTruthInput\n\n# Merge ground truth with predictions\nmonitor.create_monitoring_schedule(\n    ...\n    ground_truth_input=GroundTruthInput(\n        ground_truth_s3_uri=\"s3://bucket/ground-truth/\"\n    )\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/model-monitoring/#cloudwatch-integration","title":"CloudWatch Integration","text":"<p>Model Monitor publishes metrics to CloudWatch.</p> <pre><code># Create alarm for violations\nimport boto3\n\ncloudwatch = boto3.client(\"cloudwatch\")\n\ncloudwatch.put_metric_alarm(\n    AlarmName=\"DataDriftAlarm\",\n    MetricName=\"feature_baseline_drift_age\",\n    Namespace=\"aws/sagemaker/Endpoints/data-metrics\",\n    Statistic=\"Maximum\",\n    Period=3600,\n    EvaluationPeriods=1,\n    Threshold=0.5,\n    ComparisonOperator=\"GreaterThanThreshold\",\n    AlarmActions=[sns_topic_arn]\n)\n</code></pre>"},{"location":"domain-4-monitoring-security/model-monitoring/#exam-tips","title":"Exam Tips","text":"<p>!!! warning \"Key Points\" - Data Quality: Input feature drift detection - Model Quality: Requires ground truth labels - Bias Drift: Uses Clarify bias metrics - Feature Attribution: SHAP value changes - All monitors integrate with CloudWatch</p>"},{"location":"exam-overview/","title":"Exam Overview","text":"<p>This section provides essential information about the AWS Certified Machine Learning Engineer Associate (MLA-C01) exam.</p>"},{"location":"exam-overview/#target-candidate","title":"Target Candidate","text":"<p>The target candidate should have at least 1 year of experience using Amazon SageMaker and other AWS services for ML engineering. Background in backend software development, DevOps, data engineering, or data science is recommended.</p>"},{"location":"exam-overview/#exam-format","title":"Exam Format","text":"Attribute Details Duration 170 minutes Total Questions 65 Scored Questions 50 Unscored Questions 15 (not identified) Passing Score 720/1000"},{"location":"exam-overview/#question-types","title":"Question Types","text":"<ol> <li>Multiple Choice - One correct answer from four options</li> <li>Multiple Response - Two or more correct answers from five or more options</li> <li>Ordering - Arrange 3-5 responses in correct order</li> <li>Matching - Match responses to 3-7 prompts</li> </ol> <p>No Penalty for Guessing</p> <p>Unanswered questions are scored as incorrect. There is no penalty for guessing, so always provide an answer.</p>"},{"location":"exam-overview/#content-domains","title":"Content Domains","text":"<p>See Exam Domains for detailed breakdown of each domain.</p>"},{"location":"exam-overview/#in-scope-services","title":"In-Scope Services","text":"<p>See In-Scope AWS Services for the complete list of AWS services covered in the exam.</p>"},{"location":"exam-overview/exam-domains/","title":"Exam Domains","text":"<p>The AWS Certified Machine Learning Engineer Associate exam covers four content domains.</p>"},{"location":"exam-overview/exam-domains/#domain-1-data-preparation-for-machine-learning-28","title":"Domain 1: Data Preparation for Machine Learning (28%)","text":"<p>This domain focuses on ingesting, transforming, validating, and preparing data for ML modeling.</p>"},{"location":"exam-overview/exam-domains/#task-statements","title":"Task Statements","text":"<ul> <li>Ingest and store data for ML workloads</li> <li>Transform data and perform feature engineering</li> <li>Ensure data integrity and prepare data for modeling</li> </ul>"},{"location":"exam-overview/exam-domains/#key-services","title":"Key Services","text":"<ul> <li>Amazon S3, AWS Glue, AWS Glue DataBrew</li> <li>Amazon Kinesis, Amazon Data Firehose</li> <li>AWS Lake Formation, Amazon Athena</li> <li>SageMaker Data Wrangler, Feature Store</li> </ul>"},{"location":"exam-overview/exam-domains/#domain-2-ml-model-development-26","title":"Domain 2: ML Model Development (26%)","text":"<p>This domain covers model selection, training, tuning, evaluation, and versioning.</p>"},{"location":"exam-overview/exam-domains/#task-statements_1","title":"Task Statements","text":"<ul> <li>Choose modeling approaches based on business objectives</li> <li>Train and refine ML models</li> <li>Analyze model performance and versions</li> </ul>"},{"location":"exam-overview/exam-domains/#key-services_1","title":"Key Services","text":"<ul> <li>Amazon SageMaker (Training, Built-in Algorithms)</li> <li>SageMaker Experiments, Debugger, Clarify</li> <li>SageMaker Model Registry</li> <li>Amazon Bedrock</li> </ul>"},{"location":"exam-overview/exam-domains/#domain-3-deployment-and-orchestration-of-ml-workflows-22","title":"Domain 3: Deployment and Orchestration of ML Workflows (22%)","text":"<p>This domain focuses on deploying models and setting up CI/CD pipelines.</p>"},{"location":"exam-overview/exam-domains/#task-statements_2","title":"Task Statements","text":"<ul> <li>Select deployment infrastructure and configure endpoints</li> <li>Create and script infrastructure for ML models</li> <li>Use CI/CD pipelines to automate workflows</li> </ul>"},{"location":"exam-overview/exam-domains/#key-services_2","title":"Key Services","text":"<ul> <li>SageMaker Endpoints (Real-time, Serverless, Async)</li> <li>SageMaker Pipelines, AWS Step Functions</li> <li>Amazon ECR, ECS, EKS</li> <li>AWS CodePipeline, CodeBuild</li> </ul>"},{"location":"exam-overview/exam-domains/#domain-4-ml-solution-monitoring-maintenance-and-security-24","title":"Domain 4: ML Solution Monitoring, Maintenance, and Security (24%)","text":"<p>This domain covers monitoring, cost optimization, and security best practices.</p>"},{"location":"exam-overview/exam-domains/#task-statements_3","title":"Task Statements","text":"<ul> <li>Monitor model performance and data quality</li> <li>Monitor and optimize infrastructure and costs</li> <li>Secure AWS resources for ML</li> </ul>"},{"location":"exam-overview/exam-domains/#key-services_3","title":"Key Services","text":"<ul> <li>SageMaker Model Monitor</li> <li>Amazon CloudWatch, CloudTrail</li> <li>AWS Cost Explorer, Budgets</li> <li>IAM, KMS, Secrets Manager, Macie</li> </ul>"},{"location":"exam-overview/in-scope-services/","title":"In-Scope AWS Services","text":"<p>Complete list of AWS services covered in the MLA-C01 exam.</p>"},{"location":"exam-overview/in-scope-services/#analytics","title":"Analytics","text":"Service Key Use Cases Amazon Athena Query data in S3 using SQL Amazon Data Firehose Real-time streaming data delivery Amazon EMR Big data processing with Spark/Hadoop AWS Glue ETL, Data Catalog, crawlers AWS Glue DataBrew Visual data preparation AWS Glue Data Quality Data quality rules and monitoring Amazon Kinesis Real-time streaming data AWS Lake Formation Data lake management Amazon Managed Service for Apache Flink Stream processing Amazon OpenSearch Service Search and analytics Amazon QuickSight Business intelligence dashboards Amazon Redshift Data warehousing"},{"location":"exam-overview/in-scope-services/#machine-learning","title":"Machine Learning","text":"Service Key Use Cases Amazon Augmented AI (A2I) Human review workflows Amazon Bedrock Foundation models, GenAI Amazon CodeGuru Code reviews, profiling Amazon Comprehend NLP, text analysis Amazon Comprehend Medical Medical text analysis Amazon DevOps Guru ML-powered operations insights Amazon Fraud Detector Fraud detection AWS HealthLake Healthcare data lake Amazon Kendra Intelligent search Amazon Lex Conversational AI, chatbots Amazon Lookout for Equipment Equipment anomaly detection Amazon Lookout for Metrics Metrics anomaly detection Amazon Lookout for Vision Visual defect detection Amazon Mechanical Turk Human intelligence tasks Amazon Personalize Personalization, recommendations Amazon Polly Text-to-speech Amazon Q Generative AI assistant Amazon Rekognition Image and video analysis Amazon SageMaker Full ML platform Amazon Textract Document text extraction Amazon Transcribe Speech-to-text Amazon Translate Language translation"},{"location":"exam-overview/in-scope-services/#compute","title":"Compute","text":"Service Key Use Cases AWS Batch Batch computing jobs Amazon EC2 Virtual servers, GPU instances AWS Lambda Serverless compute AWS Serverless Application Repository Serverless app deployment"},{"location":"exam-overview/in-scope-services/#containers","title":"Containers","text":"Service Key Use Cases Amazon ECR Container image registry Amazon ECS Container orchestration Amazon EKS Kubernetes orchestration"},{"location":"exam-overview/in-scope-services/#developer-tools","title":"Developer Tools","text":"Service Key Use Cases AWS CDK Infrastructure as code AWS CodeArtifact Artifact repository AWS CodeBuild Build service AWS CodeDeploy Deployment automation AWS CodePipeline CI/CD pipelines AWS X-Ray Distributed tracing"},{"location":"exam-overview/in-scope-services/#application-integration","title":"Application Integration","text":"Service Key Use Cases Amazon EventBridge Event-driven architecture Amazon MWAA Managed Apache Airflow Amazon SNS Push notifications Amazon SQS Message queuing AWS Step Functions Workflow orchestration"},{"location":"exam-overview/in-scope-services/#management-and-governance","title":"Management and Governance","text":"Service Key Use Cases AWS Auto Scaling Automatic scaling AWS CloudFormation Infrastructure as code AWS CloudTrail API activity logging Amazon CloudWatch Monitoring and logging AWS Compute Optimizer Resource optimization AWS Config Resource compliance AWS Systems Manager Operations management AWS Trusted Advisor Best practices recommendations"},{"location":"exam-overview/in-scope-services/#security-identity-and-compliance","title":"Security, Identity, and Compliance","text":"Service Key Use Cases AWS IAM Access management AWS KMS Encryption key management Amazon Macie Data security and privacy AWS Secrets Manager Secrets management"},{"location":"exam-overview/in-scope-services/#storage","title":"Storage","text":"Service Key Use Cases Amazon EBS Block storage Amazon EFS File storage Amazon FSx Managed file systems Amazon S3 Object storage Amazon S3 Glacier Archive storage AWS Storage Gateway Hybrid storage"},{"location":"exam-overview/in-scope-services/#database","title":"Database","text":"Service Key Use Cases Amazon DocumentDB Document database Amazon DynamoDB NoSQL database Amazon ElastiCache In-memory caching Amazon Neptune Graph database Amazon RDS Relational databases"},{"location":"exam-overview/in-scope-services/#networking","title":"Networking","text":"Service Key Use Cases Amazon API Gateway API management Amazon CloudFront CDN AWS Direct Connect Dedicated network connection Amazon VPC Network isolation"},{"location":"hands-on-labs/","title":"Hands-On Labs","text":"<p>Practical labs to reinforce concepts for the MLA-C01 exam.</p>"},{"location":"hands-on-labs/#lab-index","title":"Lab Index","text":"Lab Topic Domain Difficulty Lab 01 SageMaker Data Wrangler Domain 1 Easy Lab 02 SageMaker Training Job Domain 2 Medium Lab 03 Hyperparameter Tuning Domain 2 Medium Lab 04 Endpoint Deployment Domain 3 Medium Lab 05 SageMaker Pipelines Domain 3 Hard Lab 06 Model Monitoring Domain 4 Medium"},{"location":"hands-on-labs/#prerequisites","title":"Prerequisites","text":"<p>Before starting the labs, ensure you have:</p> <ol> <li>AWS Account with appropriate permissions</li> <li>AWS CLI configured</li> <li>Python 3.9+ with boto3 installed</li> <li>SageMaker Studio or Notebook instance (optional but recommended)</li> </ol>"},{"location":"hands-on-labs/#cost-warning","title":"Cost Warning","text":"<p>AWS Costs</p> <p>These labs will incur AWS costs. To minimize expenses:</p> <pre><code>- Use the smallest instance types possible\n- Clean up resources after each lab\n- Use SageMaker Savings Plans if doing multiple labs\n- Stop notebook instances when not in use\n</code></pre>"},{"location":"hands-on-labs/#lab-structure","title":"Lab Structure","text":"<p>Each lab follows this structure:</p> <ol> <li>Objective - What you will learn</li> <li>Prerequisites - Required setup</li> <li>Steps - Detailed instructions</li> <li>Verification - How to verify success</li> <li>Cleanup - Resource cleanup instructions</li> <li>Key Takeaways - Exam-relevant points</li> </ol>"},{"location":"hands-on-labs/#getting-started","title":"Getting Started","text":"<pre><code># Clone the repository\ngit clone https://github.com/yourusername/aws-mla-study-notes-and-hands-on-labs.git\n\n# Navigate to labs\ncd aws-mla-study-notes-and-hands-on-labs\n\n# Set up Python environment\npython -m venv .venv\nsource .venv/bin/activate  # Linux/macOS\n# .venv\\Scripts\\activate   # Windows\n\n# Install dependencies\npip install boto3 sagemaker pandas\n</code></pre>"},{"location":"hands-on-labs/lab-01-data-wrangler/","title":"Lab 01: SageMaker Data Wrangler","text":"<p>Domain: 1 - Data Preparation Difficulty: Easy Time: 30 minutes</p>"},{"location":"hands-on-labs/lab-01-data-wrangler/#objective","title":"Objective","text":"<p>Learn to use SageMaker Data Wrangler for visual data preparation and feature engineering.</p>"},{"location":"hands-on-labs/lab-01-data-wrangler/#prerequisites","title":"Prerequisites","text":"<ul> <li>SageMaker Studio access</li> <li>Sample dataset (CSV)</li> </ul>"},{"location":"hands-on-labs/lab-01-data-wrangler/#steps","title":"Steps","text":""},{"location":"hands-on-labs/lab-01-data-wrangler/#step-1-access-data-wrangler","title":"Step 1: Access Data Wrangler","text":"<ol> <li>Open SageMaker Studio</li> <li>From the launcher, select \"New data flow\"</li> <li>Name your flow: <code>customer-churn-prep</code></li> </ol>"},{"location":"hands-on-labs/lab-01-data-wrangler/#step-2-import-data","title":"Step 2: Import Data","text":"<ol> <li>Click \"Import data\"</li> <li>Select \"Amazon S3\"</li> <li>Navigate to your dataset or use a sample:    <pre><code>s3://sagemaker-sample-files/datasets/tabular/synthetic/churn.csv\n</code></pre></li> <li>Click \"Import\"</li> </ol>"},{"location":"hands-on-labs/lab-01-data-wrangler/#step-3-explore-data","title":"Step 3: Explore Data","text":"<ol> <li>Click on the dataset node</li> <li>Select \"Add analysis\"</li> <li>Choose \"Table summary\" to view statistics</li> <li>Create a \"Histogram\" for numerical columns</li> </ol>"},{"location":"hands-on-labs/lab-01-data-wrangler/#step-4-add-transformations","title":"Step 4: Add Transformations","text":"<ol> <li>Click \"+\" after the data node</li> <li>Select \"Add transform\"</li> <li>Apply these transformations:</li> <li>Handle missing: Fill missing values</li> <li>Encode categorical: One-hot encode <code>State</code></li> <li>Drop columns: Remove <code>Phone</code></li> <li>Custom transform: Create new feature</li> </ol> <pre><code># Custom Pandas transform\ndf['HighUsage'] = (df['Day Mins'] &gt; df['Day Mins'].median()).astype(int)\n</code></pre>"},{"location":"hands-on-labs/lab-01-data-wrangler/#step-5-export-flow","title":"Step 5: Export Flow","text":"<ol> <li>Click \"Export\"</li> <li>Choose export destination:</li> <li>\"Export to S3\" for data</li> <li>\"Export to Pipeline\" for automation</li> <li>\"Export to Python code\" for reuse</li> </ol>"},{"location":"hands-on-labs/lab-01-data-wrangler/#verification","title":"Verification","text":"<ul> <li>Transformed dataset exported to S3</li> <li>Data quality improved (no missing values)</li> <li>Features properly encoded</li> </ul>"},{"location":"hands-on-labs/lab-01-data-wrangler/#cleanup","title":"Cleanup","text":"<ol> <li>Close Data Wrangler flow</li> <li>Delete exported files if not needed</li> <li>Stop Studio instance</li> </ol>"},{"location":"hands-on-labs/lab-01-data-wrangler/#key-takeaways","title":"Key Takeaways","text":"<p>!!! note \"Exam Points\" - Data Wrangler is visual, no-code data preparation - Supports 300+ built-in transformations - Can export to Pipelines for automation - Part of SageMaker Studio</p>"},{"location":"hands-on-labs/lab-02-training-job/","title":"Lab 02: SageMaker Training Job","text":"<p>Domain: 2 - Model Development Difficulty: Medium Time: 45 minutes</p>"},{"location":"hands-on-labs/lab-02-training-job/#objective","title":"Objective","text":"<p>Train a model using SageMaker built-in XGBoost algorithm.</p>"},{"location":"hands-on-labs/lab-02-training-job/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS CLI configured</li> <li>Python with boto3 and sagemaker SDK</li> <li>S3 bucket for data and output</li> </ul>"},{"location":"hands-on-labs/lab-02-training-job/#steps","title":"Steps","text":""},{"location":"hands-on-labs/lab-02-training-job/#step-1-prepare-data","title":"Step 1: Prepare Data","text":"<pre><code>import boto3\nimport sagemaker\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Download sample data\n!wget https://raw.githubusercontent.com/aws/amazon-sagemaker-examples/main/introduction_to_amazon_algorithms/xgboost_abalone/abalone.csv\n\n# Load and prepare\ndf = pd.read_csv('abalone.csv', header=None)\n\n# Split data\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n\n# Save to CSV (target column first for XGBoost)\ntrain_df.to_csv('train.csv', index=False, header=False)\nval_df.to_csv('validation.csv', index=False, header=False)\ntest_df.to_csv('test.csv', index=False, header=False)\n</code></pre>"},{"location":"hands-on-labs/lab-02-training-job/#step-2-upload-to-s3","title":"Step 2: Upload to S3","text":"<pre><code>sagemaker_session = sagemaker.Session()\nbucket = sagemaker_session.default_bucket()\nprefix = 'xgboost-abalone'\n\ntrain_path = sagemaker_session.upload_data('train.csv', bucket=bucket, key_prefix=f'{prefix}/train')\nval_path = sagemaker_session.upload_data('validation.csv', bucket=bucket, key_prefix=f'{prefix}/validation')\n</code></pre>"},{"location":"hands-on-labs/lab-02-training-job/#step-3-configure-training-job","title":"Step 3: Configure Training Job","text":"<pre><code>from sagemaker import image_uris\nfrom sagemaker.estimator import Estimator\n\n# Get XGBoost container\nregion = sagemaker_session.boto_region_name\nxgb_image = image_uris.retrieve('xgboost', region, version='1.5-1')\n\n# Get execution role\nrole = sagemaker.get_execution_role()\n\n# Create estimator\nxgb_estimator = Estimator(\n    image_uri=xgb_image,\n    role=role,\n    instance_count=1,\n    instance_type='ml.m5.large',\n    output_path=f's3://{bucket}/{prefix}/output',\n    sagemaker_session=sagemaker_session\n)\n\n# Set hyperparameters\nxgb_estimator.set_hyperparameters(\n    objective='reg:squarederror',\n    num_round=100,\n    max_depth=5,\n    eta=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8\n)\n</code></pre>"},{"location":"hands-on-labs/lab-02-training-job/#step-4-start-training","title":"Step 4: Start Training","text":"<pre><code>from sagemaker.inputs import TrainingInput\n\ntrain_input = TrainingInput(train_path, content_type='text/csv')\nval_input = TrainingInput(val_path, content_type='text/csv')\n\nxgb_estimator.fit({\n    'train': train_input,\n    'validation': val_input\n})\n</code></pre>"},{"location":"hands-on-labs/lab-02-training-job/#step-5-verify-training","title":"Step 5: Verify Training","text":"<pre><code># Check training job status\ntraining_job_name = xgb_estimator.latest_training_job.name\nprint(f\"Training job: {training_job_name}\")\n\n# Model artifact location\nmodel_artifact = xgb_estimator.model_data\nprint(f\"Model artifact: {model_artifact}\")\n</code></pre>"},{"location":"hands-on-labs/lab-02-training-job/#verification","title":"Verification","text":"<ul> <li>Training job completed successfully</li> <li>Model artifact saved to S3</li> <li>Training metrics available in CloudWatch</li> </ul>"},{"location":"hands-on-labs/lab-02-training-job/#cleanup","title":"Cleanup","text":"<pre><code># Delete training artifacts (optional)\nimport boto3\ns3 = boto3.resource('s3')\nbucket_obj = s3.Bucket(bucket)\nbucket_obj.objects.filter(Prefix=prefix).delete()\n</code></pre>"},{"location":"hands-on-labs/lab-02-training-job/#key-takeaways","title":"Key Takeaways","text":"<p>!!! note \"Exam Points\" - XGBoost expects target column first - Use TrainingInput for data channels - Model artifacts saved to S3 automatically - Training logs available in CloudWatch</p>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/","title":"Lab 03: Hyperparameter Tuning","text":"<p>Domain: 2 - Model Development Difficulty: Medium Time: 60 minutes</p>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#objective","title":"Objective","text":"<p>Use SageMaker Automatic Model Tuning to find optimal hyperparameters.</p>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Lab 02 (training data in S3)</li> <li>SageMaker execution role</li> </ul>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#steps","title":"Steps","text":""},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#step-1-define-hyperparameter-ranges","title":"Step 1: Define Hyperparameter Ranges","text":"<pre><code>from sagemaker.tuner import (\n    HyperparameterTuner,\n    ContinuousParameter,\n    IntegerParameter,\n    CategoricalParameter\n)\n\nhyperparameter_ranges = {\n    'eta': ContinuousParameter(0.01, 0.3),\n    'max_depth': IntegerParameter(3, 10),\n    'subsample': ContinuousParameter(0.5, 1.0),\n    'colsample_bytree': ContinuousParameter(0.5, 1.0),\n    'num_round': IntegerParameter(50, 200)\n}\n</code></pre>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#step-2-configure-tuner","title":"Step 2: Configure Tuner","text":"<pre><code>objective_metric_name = 'validation:rmse'\n\ntuner = HyperparameterTuner(\n    estimator=xgb_estimator,\n    objective_metric_name=objective_metric_name,\n    hyperparameter_ranges=hyperparameter_ranges,\n    objective_type='Minimize',\n    max_jobs=10,\n    max_parallel_jobs=2,\n    strategy='Bayesian',\n    early_stopping_type='Auto'\n)\n</code></pre>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#step-3-start-tuning-job","title":"Step 3: Start Tuning Job","text":"<pre><code>tuner.fit({\n    'train': train_input,\n    'validation': val_input\n})\n\n# Wait for completion\ntuner.wait()\n</code></pre>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#step-4-analyze-results","title":"Step 4: Analyze Results","text":"<pre><code># Get tuning job results\ntuner_analytics = tuner.analytics()\n\n# Best training job\nbest_job = tuner.best_training_job()\nprint(f\"Best job: {best_job}\")\n\n# All jobs summary\ndf_results = tuner_analytics.dataframe()\nprint(df_results.sort_values('FinalObjectiveValue').head())\n</code></pre>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#step-5-deploy-best-model","title":"Step 5: Deploy Best Model","text":"<pre><code># Deploy the best model\npredictor = tuner.deploy(\n    initial_instance_count=1,\n    instance_type='ml.m5.large',\n    endpoint_name='xgb-tuned-endpoint'\n)\n</code></pre>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#verification","title":"Verification","text":"<ul> <li>Tuning job completed with 10 training jobs</li> <li>Best hyperparameters identified</li> <li>Objective metric improved from baseline</li> </ul>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#cleanup","title":"Cleanup","text":"<pre><code># Delete endpoint\npredictor.delete_endpoint()\n\n# Delete endpoint config\nsm_client = boto3.client('sagemaker')\nsm_client.delete_endpoint_config(EndpointConfigName='xgb-tuned-endpoint')\n</code></pre>"},{"location":"hands-on-labs/lab-03-hyperparameter-tuning/#key-takeaways","title":"Key Takeaways","text":"<p>!!! note \"Exam Points\" - Bayesian strategy is most efficient for most cases - Early stopping reduces wasted compute - max_parallel_jobs affects speed and cost - Analytics provides insights into hyperparameter importance</p>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/","title":"Lab 04: Endpoint Deployment","text":"<p>Domain: 3 - Deployment &amp; Orchestration Difficulty: Medium Time: 45 minutes</p>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#objective","title":"Objective","text":"<p>Deploy models using different SageMaker endpoint types.</p>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Trained model in S3 (from Lab 02)</li> <li>SageMaker execution role</li> </ul>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#steps","title":"Steps","text":""},{"location":"hands-on-labs/lab-04-endpoint-deployment/#step-1-real-time-endpoint","title":"Step 1: Real-time Endpoint","text":"<pre><code>from sagemaker.model import Model\n\n# Create model\nmodel = Model(\n    image_uri=xgb_image,\n    model_data=model_artifact,\n    role=role,\n    sagemaker_session=sagemaker_session\n)\n\n# Deploy real-time endpoint\npredictor = model.deploy(\n    initial_instance_count=1,\n    instance_type='ml.m5.large',\n    endpoint_name='xgb-realtime-endpoint'\n)\n\n# Test prediction\nimport numpy as np\ntest_data = np.array([[0.5, 0.3, 0.2, 0.4, 0.1, 0.6, 0.7, 0.8]])\nresult = predictor.predict(test_data)\nprint(f\"Prediction: {result}\")\n</code></pre>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#step-2-serverless-endpoint","title":"Step 2: Serverless Endpoint","text":"<pre><code>from sagemaker.serverless import ServerlessInferenceConfig\n\nserverless_config = ServerlessInferenceConfig(\n    memory_size_in_mb=2048,\n    max_concurrency=5\n)\n\n# Deploy serverless endpoint\nserverless_predictor = model.deploy(\n    serverless_inference_config=serverless_config,\n    endpoint_name='xgb-serverless-endpoint'\n)\n\n# Test (note: may have cold start delay)\nresult = serverless_predictor.predict(test_data)\nprint(f\"Serverless prediction: {result}\")\n</code></pre>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#step-3-async-endpoint","title":"Step 3: Async Endpoint","text":"<pre><code>from sagemaker.async_inference import AsyncInferenceConfig\n\nasync_config = AsyncInferenceConfig(\n    output_path=f's3://{bucket}/{prefix}/async-output/',\n    max_concurrent_invocations_per_instance=4\n)\n\n# Deploy async endpoint\nasync_predictor = model.deploy(\n    initial_instance_count=1,\n    instance_type='ml.m5.large',\n    async_inference_config=async_config,\n    endpoint_name='xgb-async-endpoint'\n)\n</code></pre>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#step-4-invoke-async-endpoint","title":"Step 4: Invoke Async Endpoint","text":"<pre><code>import json\n\n# Upload input to S3\ninput_data = json.dumps(test_data.tolist())\ninput_key = f'{prefix}/async-input/input.json'\ns3_client = boto3.client('s3')\ns3_client.put_object(Bucket=bucket, Key=input_key, Body=input_data)\n\n# Invoke async\nsm_runtime = boto3.client('sagemaker-runtime')\nresponse = sm_runtime.invoke_endpoint_async(\n    EndpointName='xgb-async-endpoint',\n    InputLocation=f's3://{bucket}/{input_key}',\n    ContentType='application/json'\n)\n\noutput_location = response['OutputLocation']\nprint(f\"Output will be at: {output_location}\")\n</code></pre>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#step-5-compare-endpoints","title":"Step 5: Compare Endpoints","text":"Endpoint Type Latency Cost Use Case Real-time Low High (always-on) Interactive apps Serverless Variable Low (pay-per-use) Variable traffic Async High Medium Large payloads"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#verification","title":"Verification","text":"<ul> <li>All three endpoints deployed successfully</li> <li>Predictions returned correctly</li> <li>Understand trade-offs between endpoint types</li> </ul>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#cleanup","title":"Cleanup","text":"<pre><code># Delete all endpoints\nfor endpoint in ['xgb-realtime-endpoint', 'xgb-serverless-endpoint', 'xgb-async-endpoint']:\n    try:\n        sm_client.delete_endpoint(EndpointName=endpoint)\n        sm_client.delete_endpoint_config(EndpointConfigName=endpoint)\n    except:\n        pass\n\n# Delete model\nsm_client.delete_model(ModelName=model.name)\n</code></pre>"},{"location":"hands-on-labs/lab-04-endpoint-deployment/#key-takeaways","title":"Key Takeaways","text":"<p>!!! note \"Exam Points\" - Real-time: Consistent, low-latency needs - Serverless: Cost optimization, variable traffic - Async: Large payloads, long processing - Always clean up endpoints to avoid charges</p>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/","title":"Lab 05: SageMaker Pipelines","text":"<p>Domain: 3 - Deployment &amp; Orchestration Difficulty: Hard Time: 90 minutes</p>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#objective","title":"Objective","text":"<p>Build an end-to-end ML pipeline using SageMaker Pipelines.</p>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#prerequisites","title":"Prerequisites","text":"<ul> <li>Training data in S3</li> <li>Understanding of SageMaker training and deployment</li> </ul>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#steps","title":"Steps","text":""},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#step-1-define-pipeline-parameters","title":"Step 1: Define Pipeline Parameters","text":"<pre><code>from sagemaker.workflow.parameters import (\n    ParameterString,\n    ParameterInteger,\n    ParameterFloat\n)\n\ninput_data = ParameterString(name=\"InputData\", default_value=f\"s3://{bucket}/{prefix}/data/\")\ninstance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.large\")\nmodel_approval_status = ParameterString(name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\")\n</code></pre>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#step-2-define-processing-step","title":"Step 2: Define Processing Step","text":"<pre><code>from sagemaker.sklearn.processing import SKLearnProcessor\nfrom sagemaker.processing import ProcessingInput, ProcessingOutput\nfrom sagemaker.workflow.steps import ProcessingStep\n\nsklearn_processor = SKLearnProcessor(\n    framework_version=\"1.0-1\",\n    instance_type=\"ml.m5.large\",\n    instance_count=1,\n    role=role,\n    sagemaker_session=sagemaker_session\n)\n\nprocessing_step = ProcessingStep(\n    name=\"PreprocessData\",\n    processor=sklearn_processor,\n    inputs=[\n        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\")\n    ],\n    outputs=[\n        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\")\n    ],\n    code=\"preprocessing.py\"\n)\n</code></pre>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#step-3-define-training-step","title":"Step 3: Define Training Step","text":"<pre><code>from sagemaker.workflow.steps import TrainingStep\nfrom sagemaker.inputs import TrainingInput\n\ntraining_step = TrainingStep(\n    name=\"TrainModel\",\n    estimator=xgb_estimator,\n    inputs={\n        \"train\": TrainingInput(\n            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n            content_type=\"text/csv\"\n        ),\n        \"validation\": TrainingInput(\n            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n            content_type=\"text/csv\"\n        )\n    }\n)\n</code></pre>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#step-4-define-evaluation-step","title":"Step 4: Define Evaluation Step","text":"<pre><code>from sagemaker.workflow.steps import ProcessingStep\nfrom sagemaker.workflow.properties import PropertyFile\n\nevaluation_report = PropertyFile(\n    name=\"EvaluationReport\",\n    output_name=\"evaluation\",\n    path=\"evaluation.json\"\n)\n\nevaluation_step = ProcessingStep(\n    name=\"EvaluateModel\",\n    processor=sklearn_processor,\n    inputs=[\n        ProcessingInput(\n            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n            destination=\"/opt/ml/processing/model\"\n        ),\n        ProcessingInput(\n            source=processing_step.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n            destination=\"/opt/ml/processing/test\"\n        )\n    ],\n    outputs=[\n        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\")\n    ],\n    code=\"evaluation.py\",\n    property_files=[evaluation_report]\n)\n</code></pre>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#step-5-define-condition-step","title":"Step 5: Define Condition Step","text":"<pre><code>from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\nfrom sagemaker.workflow.condition_step import ConditionStep\nfrom sagemaker.workflow.functions import JsonGet\n\ncondition = ConditionGreaterThanOrEqualTo(\n    left=JsonGet(\n        step_name=evaluation_step.name,\n        property_file=evaluation_report,\n        json_path=\"metrics.accuracy.value\"\n    ),\n    right=0.8\n)\n</code></pre>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#step-6-define-register-model-step","title":"Step 6: Define Register Model Step","text":"<pre><code>from sagemaker.workflow.model_step import ModelStep\nfrom sagemaker.model import Model\n\nmodel = Model(\n    image_uri=xgb_image,\n    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n    role=role\n)\n\nregister_step = ModelStep(\n    name=\"RegisterModel\",\n    step_args=model.register(\n        content_types=[\"text/csv\"],\n        response_types=[\"text/csv\"],\n        inference_instances=[\"ml.m5.large\"],\n        transform_instances=[\"ml.m5.large\"],\n        model_package_group_name=\"my-model-group\",\n        approval_status=model_approval_status\n    )\n)\n</code></pre>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#step-7-create-and-execute-pipeline","title":"Step 7: Create and Execute Pipeline","text":"<pre><code>from sagemaker.workflow.pipeline import Pipeline\n\npipeline = Pipeline(\n    name=\"my-ml-pipeline\",\n    parameters=[input_data, instance_type, model_approval_status],\n    steps=[processing_step, training_step, evaluation_step,\n           ConditionStep(\n               name=\"CheckAccuracy\",\n               conditions=[condition],\n               if_steps=[register_step],\n               else_steps=[]\n           )]\n)\n\n# Create/update pipeline\npipeline.upsert(role_arn=role)\n\n# Start execution\nexecution = pipeline.start()\nexecution.wait()\n</code></pre>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#verification","title":"Verification","text":"<ul> <li>Pipeline created successfully</li> <li>All steps executed in order</li> <li>Model registered if accuracy threshold met</li> </ul>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#cleanup","title":"Cleanup","text":"<pre><code># Delete pipeline\npipeline.delete()\n</code></pre>"},{"location":"hands-on-labs/lab-05-sagemaker-pipelines/#key-takeaways","title":"Key Takeaways","text":"<p>!!! note \"Exam Points\" - Pipelines automate end-to-end ML workflows - ConditionStep gates deployment on quality - PropertyFile extracts metrics from processing output - Parameters make pipelines reusable</p>"},{"location":"hands-on-labs/lab-06-model-monitoring/","title":"Lab 06: Model Monitoring","text":"<p>Domain: 4 - Monitoring &amp; Security Difficulty: Medium Time: 60 minutes</p>"},{"location":"hands-on-labs/lab-06-model-monitoring/#objective","title":"Objective","text":"<p>Set up SageMaker Model Monitor to detect data drift in production.</p>"},{"location":"hands-on-labs/lab-06-model-monitoring/#prerequisites","title":"Prerequisites","text":"<ul> <li>Deployed endpoint (from Lab 04)</li> <li>Baseline data</li> </ul>"},{"location":"hands-on-labs/lab-06-model-monitoring/#steps","title":"Steps","text":""},{"location":"hands-on-labs/lab-06-model-monitoring/#step-1-create-baseline","title":"Step 1: Create Baseline","text":"<pre><code>from sagemaker.model_monitor import DefaultModelMonitor\nfrom sagemaker.model_monitor.dataset_format import DatasetFormat\n\n# Create monitor\nmonitor = DefaultModelMonitor(\n    role=role,\n    instance_count=1,\n    instance_type='ml.m5.large',\n    volume_size_in_gb=20,\n    max_runtime_in_seconds=3600\n)\n\n# Create baseline from training data\nbaseline_job = monitor.suggest_baseline(\n    baseline_dataset=f's3://{bucket}/{prefix}/train/train.csv',\n    dataset_format=DatasetFormat.csv(header=False),\n    output_s3_uri=f's3://{bucket}/{prefix}/baseline/',\n    wait=True\n)\n</code></pre>"},{"location":"hands-on-labs/lab-06-model-monitoring/#step-2-examine-baseline","title":"Step 2: Examine Baseline","text":"<pre><code># Get baseline statistics\nbaseline_stats = monitor.baseline_statistics()\nprint(baseline_stats.body_dict)\n\n# Get baseline constraints\nbaseline_constraints = monitor.suggested_constraints()\nprint(baseline_constraints.body_dict)\n</code></pre>"},{"location":"hands-on-labs/lab-06-model-monitoring/#step-3-enable-data-capture","title":"Step 3: Enable Data Capture","text":"<pre><code>from sagemaker.model_monitor import DataCaptureConfig\n\ndata_capture_config = DataCaptureConfig(\n    enable_capture=True,\n    sampling_percentage=100,\n    destination_s3_uri=f's3://{bucket}/{prefix}/data-capture/',\n    capture_options=[\"REQUEST\", \"RESPONSE\"]\n)\n\n# Update endpoint with data capture\npredictor.update_data_capture_config(data_capture_config)\n</code></pre>"},{"location":"hands-on-labs/lab-06-model-monitoring/#step-4-create-monitoring-schedule","title":"Step 4: Create Monitoring Schedule","text":"<pre><code>from sagemaker.model_monitor import CronExpressionGenerator\n\nmonitor.create_monitoring_schedule(\n    monitor_schedule_name='my-monitoring-schedule',\n    endpoint_input=endpoint_name,\n    output_s3_uri=f's3://{bucket}/{prefix}/monitoring-output/',\n    statistics=baseline_stats,\n    constraints=baseline_constraints,\n    schedule_cron_expression=CronExpressionGenerator.hourly()\n)\n</code></pre>"},{"location":"hands-on-labs/lab-06-model-monitoring/#step-5-generate-traffic-and-check-results","title":"Step 5: Generate Traffic and Check Results","text":"<pre><code>import time\nimport numpy as np\n\n# Generate some predictions\nfor i in range(100):\n    test_data = np.random.rand(1, 8)\n    predictor.predict(test_data)\n\n# Wait for monitoring execution\nprint(\"Waiting for monitoring execution...\")\ntime.sleep(3600)  # Wait 1 hour for scheduled execution\n\n# Check monitoring results\nexecutions = monitor.list_executions()\nlatest_execution = executions[-1]\nprint(f\"Status: {latest_execution.describe()['ProcessingJobStatus']}\")\n</code></pre>"},{"location":"hands-on-labs/lab-06-model-monitoring/#step-6-create-cloudwatch-alarm","title":"Step 6: Create CloudWatch Alarm","text":"<pre><code>cloudwatch = boto3.client('cloudwatch')\n\ncloudwatch.put_metric_alarm(\n    AlarmName='DataDriftAlarm',\n    AlarmDescription='Alert when data drift detected',\n    MetricName='feature_baseline_drift_violation',\n    Namespace='aws/sagemaker/Endpoints/data-metrics',\n    Dimensions=[\n        {'Name': 'Endpoint', 'Value': endpoint_name},\n        {'Name': 'MonitoringSchedule', 'Value': 'my-monitoring-schedule'}\n    ],\n    Statistic='Sum',\n    Period=3600,\n    EvaluationPeriods=1,\n    Threshold=1,\n    ComparisonOperator='GreaterThanOrEqualTo',\n    AlarmActions=[sns_topic_arn]\n)\n</code></pre>"},{"location":"hands-on-labs/lab-06-model-monitoring/#verification","title":"Verification","text":"<ul> <li>Baseline statistics generated</li> <li>Monitoring schedule running</li> <li>Data capture enabled</li> <li>CloudWatch alarm configured</li> </ul>"},{"location":"hands-on-labs/lab-06-model-monitoring/#cleanup","title":"Cleanup","text":"<pre><code># Stop monitoring schedule\nmonitor.stop_monitoring_schedule()\nmonitor.delete_monitoring_schedule()\n\n# Delete endpoint\npredictor.delete_endpoint()\n</code></pre>"},{"location":"hands-on-labs/lab-06-model-monitoring/#key-takeaways","title":"Key Takeaways","text":"<p>!!! note \"Exam Points\" - Baseline is created from training data - Data capture records endpoint traffic - Monitoring schedule runs periodically - Violations trigger CloudWatch metrics - Integrate with SNS for alerts</p>"},{"location":"practice-exams/","title":"Practice Exams","text":"<p>Practice exams to test your knowledge before the MLA-C01 exam.</p>"},{"location":"practice-exams/#exam-format","title":"Exam Format","text":"<p>Each practice exam contains 65 questions mirroring the real exam:</p> Domain Questions Weight Domain 1: Data Preparation ~18 28% Domain 2: Model Development ~17 26% Domain 3: Deployment &amp; Orchestration ~14 22% Domain 4: Monitoring &amp; Security ~16 24%"},{"location":"practice-exams/#available-practice-exams","title":"Available Practice Exams","text":"Exam Questions Time Status Practice Exam 01 65 170 min Available Practice Exam 02 65 170 min Available"},{"location":"practice-exams/#question-types","title":"Question Types","text":"<p>The exam includes these question types:</p> <ol> <li>Multiple Choice - Select one correct answer</li> <li>Multiple Response - Select all correct answers</li> <li>Ordering - Arrange steps in correct order</li> <li>Matching - Match items to descriptions</li> </ol>"},{"location":"practice-exams/#how-to-use","title":"How to Use","text":"<ol> <li>Set a timer for 170 minutes</li> <li>Answer all questions without looking at answers</li> <li>Review your answers</li> <li>Check the answer explanations</li> <li>Note topics that need more study</li> </ol>"},{"location":"practice-exams/#scoring","title":"Scoring","text":"<ul> <li>Target: 720/1000 to pass</li> <li>Each question weighted equally (scored questions only)</li> <li>No penalty for wrong answers</li> </ul>"},{"location":"practice-exams/#answer-format","title":"Answer Format","text":"<p>Questions use collapsible answers:</p> <pre><code>&lt;details&gt;\n&lt;summary&gt;Answer&lt;/summary&gt;\n\n**B. Correct Answer**\n\nExplanation of why this is correct and why\nother options are incorrect.\n\n**Domain**: X - Domain Name\n\n&lt;/details&gt;\n</code></pre>"},{"location":"practice-exams/#study-tips","title":"Study Tips","text":"<p>!!! tip \"After Each Practice Exam\" 1. Review all incorrect answers 2. Note recurring topics 3. Re-read relevant study notes 4. Try related hands-on labs 5. Retake after a few days</p>"},{"location":"practice-exams/exam-01/","title":"Practice Exam 01","text":"<p>Time Limit: 170 minutes Questions: 65 Passing Score: 720/1000</p>"},{"location":"practice-exams/exam-01/#question-1","title":"Question 1","text":"<p>A machine learning engineer needs to deploy a model that receives thousands of inference requests per second with sub-100ms latency requirements. The traffic pattern is consistent throughout business hours. Which SageMaker deployment option should they use?</p> <p>A. Serverless Inference endpoint B. Real-time Inference endpoint with Auto Scaling C. Asynchronous Inference endpoint D. Batch Transform job</p> Answer  **B. Real-time Inference endpoint with Auto Scaling**  Real-time endpoints provide consistent low-latency inference. Auto Scaling handles the high request volume. Serverless has cold start delays unsuitable for strict latency requirements. Async and Batch are not real-time solutions.  **Domain**: 3 - Deployment and Orchestration"},{"location":"practice-exams/exam-01/#question-2","title":"Question 2","text":"<p>A data scientist is preparing training data stored in Amazon S3. The dataset contains 500GB of CSV files. They need to efficiently load this data for SageMaker training. Which approach is MOST appropriate?</p> <p>A. Use File mode with ml.m5.xlarge instance B. Use Pipe mode with RecordIO format C. Use FastFile mode with Parquet format D. Download data to local disk before training</p> Answer  **B. Use Pipe mode with RecordIO format**  Pipe mode streams data directly from S3, eliminating download time for large datasets. RecordIO is optimized for streaming. File mode requires downloading all data first. FastFile is good for random access but Pipe is better for sequential training access.  **Domain**: 1 - Data Preparation"},{"location":"practice-exams/exam-01/#question-3","title":"Question 3","text":"<p>A company wants to detect when their deployed fraud detection model starts receiving input data that differs significantly from training data. Which AWS service should they use?</p> <p>A. Amazon CloudWatch Logs B. AWS CloudTrail C. SageMaker Model Monitor D. SageMaker Debugger</p> Answer  **C. SageMaker Model Monitor**  Model Monitor specifically detects data drift by comparing production data against baseline statistics from training data. CloudWatch Logs captures application logs. CloudTrail audits API calls. Debugger monitors training, not inference.  **Domain**: 4 - Monitoring and Security"},{"location":"practice-exams/exam-01/#question-4","title":"Question 4","text":"<p>A team needs to automate their ML workflow including data preprocessing, training, evaluation, and conditional model registration. The model should only be registered if accuracy exceeds 85%. Which service is BEST suited for this?</p> <p>A. AWS Step Functions B. Amazon MWAA (Managed Airflow) C. SageMaker Pipelines D. AWS Glue Workflows</p> Answer  **C. SageMaker Pipelines**  SageMaker Pipelines is purpose-built for ML workflows with native support for conditional steps, model registration, and integration with SageMaker components. Step Functions works but lacks ML-specific features like caching and lineage. MWAA is more general-purpose. Glue is for data workflows.  **Domain**: 3 - Deployment and Orchestration"},{"location":"practice-exams/exam-01/#question-5","title":"Question 5","text":"<p>An ML engineer needs to store and manage features that will be used for both batch training and real-time inference. The same features should be available with low latency for predictions and for offline training jobs. Which solution should they use?</p> <p>A. Amazon DynamoDB for online, S3 for offline B. SageMaker Feature Store with Online and Offline stores C. Amazon ElastiCache for online, Redshift for offline D. Amazon RDS for both online and offline</p> Answer  **B. SageMaker Feature Store with Online and Offline stores**  SageMaker Feature Store provides both Online store (low latency, DynamoDB-backed) and Offline store (S3-backed for training) from a single feature definition. This ensures consistency between training and inference features. Custom solutions require more management.  **Domain**: 1 - Data Preparation"},{"location":"practice-exams/exam-01/#question-6","title":"Question 6","text":"<p>A company wants to reduce their SageMaker training costs by up to 90% for non-time-critical workloads. Which approach should they implement?</p> <p>A. Use smaller instance types B. Use Spot Training with checkpointing C. Use Savings Plans D. Reduce training epochs</p> Answer  **B. Use Spot Training with checkpointing**  Spot Training can reduce costs by up to 90% by using spare EC2 capacity. Checkpointing ensures training can resume if interrupted. Savings Plans offer up to 64% savings. Smaller instances may increase training time. Reducing epochs may hurt model quality.  **Domain**: 4 - Monitoring and Security (Cost Optimization)"},{"location":"practice-exams/exam-01/#question-7","title":"Question 7","text":"<p>A data engineer needs to automatically discover the schema of new data files landing in S3 and make them queryable via Athena. Which AWS Glue component should they use?</p> <p>A. AWS Glue ETL Jobs B. AWS Glue Crawlers C. AWS Glue DataBrew D. AWS Glue Triggers</p> Answer  **B. AWS Glue Crawlers**  Glue Crawlers automatically scan data sources, infer schemas, and populate the Glue Data Catalog. Tables in the Data Catalog are automatically queryable by Athena. ETL Jobs transform data. DataBrew is for visual data prep. Triggers schedule jobs.  **Domain**: 1 - Data Preparation"},{"location":"practice-exams/exam-01/#question-8","title":"Question 8","text":"<p>An ML team wants to explain individual predictions from their XGBoost model to business stakeholders. They need to show which features contributed most to each prediction. Which SageMaker capability should they use?</p> <p>A. SageMaker Debugger B. SageMaker Clarify with SHAP C. SageMaker Experiments D. SageMaker Model Monitor</p> Answer  **B. SageMaker Clarify with SHAP**  SageMaker Clarify provides model explainability using SHAP (SHapley Additive exPlanations) values to show feature contributions to individual predictions. Debugger monitors training. Experiments tracks runs. Model Monitor detects drift.  **Domain**: 2 - Model Development"},{"location":"practice-exams/exam-01/#question-9","title":"Question 9","text":"<p>A company is building a customer support chatbot that needs to access their internal knowledge base documents to answer questions accurately. Which Amazon Bedrock feature should they use?</p> <p>A. Bedrock Agents B. Bedrock Fine-tuning C. Bedrock Knowledge Bases D. Bedrock Guardrails</p> Answer  **C. Bedrock Knowledge Bases**  Knowledge Bases implement RAG (Retrieval Augmented Generation) by connecting foundation models to your data. Documents are chunked, embedded, and stored in a vector database for retrieval. Agents automate tasks. Fine-tuning customizes models. Guardrails filter content.  **Domain**: 2 - Model Development"},{"location":"practice-exams/exam-01/#question-10","title":"Question 10","text":"<p>A machine learning engineer needs to ensure that their SageMaker training job output and model artifacts are encrypted at rest using a customer-managed key. Which AWS service should they use?</p> <p>A. AWS Secrets Manager B. AWS Certificate Manager C. AWS Key Management Service (KMS) D. AWS CloudHSM</p> Answer  **C. AWS Key Management Service (KMS)**  KMS provides customer-managed encryption keys that can be specified in SageMaker training job configuration for encrypting output data and model artifacts. Secrets Manager stores credentials. Certificate Manager handles SSL/TLS. CloudHSM is for dedicated hardware security modules.  **Domain**: 4 - Monitoring and Security   <p>Continue adding more questions following this format...</p>"},{"location":"practice-exams/exam-01/#question-65","title":"Question 65","text":"<p>A company needs to process ML inference requests that may take up to 15 minutes to complete. Request payloads can be up to 500MB. The application can tolerate delays as results are processed asynchronously. Which SageMaker endpoint type should they use?</p> <p>A. Real-time Inference B. Serverless Inference C. Asynchronous Inference D. Multi-Model Endpoint</p> Answer  **C. Asynchronous Inference**  Asynchronous Inference supports payloads up to 1GB and processing times up to 15 minutes. Results are stored in S3 and can trigger SNS notifications. Real-time and Serverless have 60-second timeouts and 6MB payload limits. Multi-Model hosts multiple models but doesn't extend timeouts.  **Domain**: 3 - Deployment and Orchestration"},{"location":"practice-exams/exam-01/#end-of-practice-exam-01","title":"End of Practice Exam 01","text":"<p>Review your answers and study the explanations for any questions you got wrong.</p>"},{"location":"practice-exams/exam-02/","title":"Practice Exam 02","text":"<p>Time Limit: 170 minutes Questions: 65 Passing Score: 720/1000</p>"},{"location":"practice-exams/exam-02/#question-1","title":"Question 1","text":"<p>A data scientist needs to train an image classification model on a dataset of 1 million images. The model requires GPU acceleration. Which SageMaker instance type is MOST appropriate for this training job?</p> <p>A. ml.m5.4xlarge B. ml.c5.4xlarge C. ml.p3.2xlarge D. ml.r5.4xlarge</p> Answer  **C. ml.p3.2xlarge**  P3 instances have NVIDIA V100 GPUs optimized for deep learning training. Image classification is compute-intensive and benefits significantly from GPU acceleration. M5 is general purpose, C5 is CPU compute-optimized, R5 is memory-optimized.  **Domain**: 2 - Model Development"},{"location":"practice-exams/exam-02/#question-2","title":"Question 2","text":"<p>A company has deployed a real-time endpoint but wants to reduce costs during nights and weekends when traffic is minimal. Which approach provides the BEST cost optimization while maintaining availability?</p> <p>A. Delete the endpoint and recreate it when needed B. Use Serverless Inference instead C. Configure Auto Scaling with scheduled actions D. Reduce the instance type during off-peak hours</p> Answer  **C. Configure Auto Scaling with scheduled actions**  Scheduled Auto Scaling can reduce capacity during known low-traffic periods while maintaining availability. Serverless might have cold start issues. Deleting endpoints causes downtime. Instance type changes require endpoint updates.  **Domain**: 3 - Deployment and Orchestration"},{"location":"practice-exams/exam-02/#question-3","title":"Question 3","text":"<p>An ML engineer needs to validate data quality before training. They want to check for null values, unique constraints, and value ranges. Which AWS service provides built-in data quality rules?</p> <p>A. SageMaker Data Wrangler B. AWS Glue Data Quality C. Amazon Macie D. AWS Config</p> Answer  **B. AWS Glue Data Quality**  Glue Data Quality provides built-in rules for completeness, uniqueness, accuracy, and custom validations. Data Wrangler is for visual data prep. Macie detects sensitive data. Config tracks resource compliance.  **Domain**: 1 - Data Preparation"},{"location":"practice-exams/exam-02/#question-4","title":"Question 4","text":"<p>A team wants to track and compare multiple training runs with different hyperparameters. They need to log metrics, parameters, and artifacts for each run. Which SageMaker feature should they use?</p> <p>A. SageMaker Model Registry B. SageMaker Experiments C. SageMaker Model Monitor D. SageMaker Debugger</p> Answer  **B. SageMaker Experiments**  Experiments provides tracking for ML runs including metrics, parameters, and artifacts. It enables comparison across runs and organizing experiments. Model Registry is for versioning approved models. Model Monitor tracks production drift. Debugger analyzes training issues.  **Domain**: 2 - Model Development"},{"location":"practice-exams/exam-02/#question-5","title":"Question 5","text":"<p>A company needs to detect personally identifiable information (PII) in their ML training data stored in S3. Which AWS service should they use?</p> <p>A. AWS Glue Data Quality B. Amazon Comprehend C. Amazon Macie D. AWS Config</p> Answer  **C. Amazon Macie**  Macie uses ML to automatically discover, classify, and protect sensitive data including PII in S3. Comprehend can detect PII in text but isn't designed for S3 scanning. Glue Data Quality checks data integrity. Config tracks resource compliance.  **Domain**: 4 - Monitoring and Security"},{"location":"practice-exams/exam-02/#question-6","title":"Question 6","text":"<p>An ML team needs to deploy multiple similar models (one per customer) efficiently. Each model is about 500MB and inference logic is identical. Which SageMaker deployment approach is MOST cost-effective?</p> <p>A. Deploy separate endpoints for each model B. Use Multi-Model Endpoint C. Use Serverless Inference for each model D. Use Multi-Container Endpoint</p> Answer  **B. Use Multi-Model Endpoint**  Multi-Model Endpoints host multiple models on shared infrastructure, loading models dynamically. This is ideal for many similar models with sparse individual usage. Separate endpoints waste resources. Serverless has cold starts. Multi-Container is for different inference logic.  **Domain**: 3 - Deployment and Orchestration"},{"location":"practice-exams/exam-02/#question-7","title":"Question 7","text":"<p>A data engineer needs to stream real-time clickstream data from their website directly into S3 for ML processing. Which AWS service should they use?</p> <p>A. Amazon Kinesis Data Streams B. Amazon Kinesis Data Firehose C. Amazon SQS D. Amazon SNS</p> Answer  **B. Amazon Kinesis Data Firehose**  Firehose automatically delivers streaming data to S3 (and other destinations) without requiring consumer code. Data Streams requires custom consumers. SQS is for message queuing. SNS is for pub/sub notifications.  **Domain**: 1 - Data Preparation"},{"location":"practice-exams/exam-02/#question-8","title":"Question 8","text":"<p>A company wants to use Claude 3 through Amazon Bedrock but needs to ensure the model doesn't generate responses about certain competitors. Which Bedrock feature should they configure?</p> <p>A. Fine-tuning B. Knowledge Bases C. Guardrails D. Agents</p> Answer  **C. Guardrails**  Guardrails allows you to configure denied topics, content filters, and word filters to control model outputs. Fine-tuning changes model behavior through training. Knowledge Bases adds context. Agents automate tasks.  **Domain**: 2 - Model Development"},{"location":"practice-exams/exam-02/#question-9","title":"Question 9","text":"<p>An ML engineer needs to run a SageMaker notebook instance in a private subnet without internet access while still accessing S3 and SageMaker services. What should they configure?</p> <p>A. NAT Gateway B. VPC Endpoints C. Internet Gateway D. AWS Direct Connect</p> Answer  **B. VPC Endpoints**  VPC Endpoints (Interface and Gateway) provide private connectivity to AWS services without requiring internet access. NAT and Internet Gateways provide internet access. Direct Connect is for on-premises connectivity.  **Domain**: 4 - Monitoring and Security"},{"location":"practice-exams/exam-02/#question-10","title":"Question 10","text":"<p>A company is using XGBoost for binary classification. They want to automatically find the best combination of learning rate, max depth, and number of trees. Which SageMaker feature should they use?</p> <p>A. SageMaker Autopilot B. SageMaker Automatic Model Tuning C. SageMaker JumpStart D. SageMaker Clarify</p> Answer  **B. SageMaker Automatic Model Tuning**  Automatic Model Tuning (Hyperparameter Optimization) systematically searches for optimal hyperparameters. Autopilot automates the entire ML process. JumpStart provides pre-trained models. Clarify is for bias and explainability.  **Domain**: 2 - Model Development   <p>Continue adding more questions following this format...</p>"},{"location":"practice-exams/exam-02/#end-of-practice-exam-02","title":"End of Practice Exam 02","text":"<p>Review your answers and study the explanations for any questions you got wrong.</p>"}]}